# Cassandra é¡¹ç›®æŠ€æœ¯åˆ†ææŠ¥å‘Š
## Bio-Short-Seller ç”Ÿç‰©åŒ»å­¦å°½èŒè°ƒæŸ¥å¹³å°

---

## ğŸ“‹ ç›®å½•
1. [é¡¹ç›®æ¦‚è§ˆ](#1-é¡¹ç›®æ¦‚è§ˆ)
2. [å·¥ä½œæµç¨‹åˆ†æ](#2-å·¥ä½œæµç¨‹åˆ†æ)
3. [æ•°æ®æµåˆ†æ](#3-æ•°æ®æµåˆ†æ)
4. [Final Report ç»„æˆè§£æ](#4-final-report-ç»„æˆè§£æ)
5. ["Data not available" æ ¹å› åˆ†æ](#5-data-not-available-æ ¹å› åˆ†æ)
6. [å…³é”®ä»£ç è·¯å¾„](#6-å…³é”®ä»£ç è·¯å¾„)
7. [æ”¹è¿›å»ºè®®](#7-æ”¹è¿›å»ºè®®)

---

## 1. é¡¹ç›®æ¦‚è§ˆ

### 1.1 é¡¹ç›®å®šä½
**Cassandra** æ˜¯ä¸€ä¸ªåŸºäº AI çš„ç”Ÿç‰©åŒ»å­¦å°½èŒè°ƒæŸ¥å¹³å°ï¼Œä¸“é—¨ç”¨äºï¼š
- å‘æ˜ç§‘ç ”è®ºæ–‡ä¸­çš„"æš—æ•°æ®"ï¼ˆburied negative resultsï¼‰
- æ£€æµ‹ä¸´åºŠè¯•éªŒå¤±è´¥ä¿¡å·
- è¿›è¡Œç§‘å­¦å›¾åƒå–è¯åˆ†æ
- ç”ŸæˆæŠ•èµ„çº§é£é™©è¯„ä¼°æŠ¥å‘Š

### 1.2 æ ¸å¿ƒæŠ€æœ¯æ ˆ
```
Frontend:  Flask + SocketIO (å®æ—¶è¿›åº¦æ¨é€)
Backend:   LangGraph (å¤šæ™ºèƒ½ä½“ç¼–æ’)
LLM:       Google Gemini Pro (2M token context window)
Database:  Neo4j (çŸ¥è¯†å›¾è°±, å¯é€‰)
PDFå¤„ç†:   PyMuPDF, PDFMiner
å›¾åƒåˆ†æ:  Gemini Vision API
```

### 1.3 ä¸‰å¤§æ ¸å¿ƒå¼•æ“
| å¼•æ“ | èŒè´£ | è¾“å‡º |
|-----|------|------|
| **BioHarvestEngine** | æ–‡çŒ®/ä¸´åºŠè¯•éªŒæ”¶é›† | PubMedè®ºæ–‡ + ClinicalTrials.govæ•°æ® + PDFä¸‹è½½ |
| **EvidenceEngine** | æš—æ•°æ®æŒ–æ˜ | è¡¥å……ææ–™ä¸­çš„è´Ÿé¢ç»“æœã€ç»Ÿè®¡çº¢æ—— |
| **ForensicEngine** | å›¾åƒå–è¯ | å¯ç–‘å›¾åƒæ ‡è®°ï¼ˆWestern Blotæ‹¼æ¥ç­‰ï¼‰ |

---

## 2. å·¥ä½œæµç¨‹åˆ†æ

### 2.1 å®Œæ•´å·¥ä½œæµ (LangGraph Orchestration)

```
ç”¨æˆ·è¾“å…¥æŸ¥è¯¢
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SUPERVISOR (src/agents/supervisor.py)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NODE 1: HARVESTER (BioHarvestEngine/agent.py)    â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚ â€¢ ç”Ÿæˆæœç´¢æŸ¥è¯¢ (LLM: Gemini Pro)                    â”‚
â”‚ â€¢ å¹¶è¡Œæœç´¢:                                        â”‚
â”‚   â”œâ”€ EuroPMC (PRIMARY - ç›´æ¥PDFä¸‹è½½)              â”‚
â”‚   â”œâ”€ PubMed (FALLBACK - æ–‡çŒ®å…ƒæ•°æ®)               â”‚
â”‚   â””â”€ ClinicalTrials.gov (å¤±è´¥è¯•éªŒæŒ–æ˜)            â”‚
â”‚ â€¢ PDFä¸‹è½½åˆ°æœ¬åœ°: downloads/pmc_pdfs/              â”‚
â”‚                                                   â”‚
â”‚ OUTPUT:                                           â”‚
â”‚   - harvested_data: List[Dict] (è®ºæ–‡/è¯•éªŒå…ƒæ•°æ®)  â”‚
â”‚   - pdf_paths: List[str] (æœ¬åœ°PDFè·¯å¾„)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PARALLEL EXECUTION (å¹¶è¡ŒèŠ‚ç‚¹)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ NODE 2A: MINER              â”‚ NODE 2B: AUDITOR             â”‚
â”‚ (EvidenceEngine/agent.py)   â”‚ (ForensicEngine/agent.py)    â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ â€¢ è¯»å–æ¯ä¸ªPDF               â”‚ â€¢ æå–PDFä¸­çš„å›¾åƒ            â”‚
â”‚ â€¢ ä½¿ç”¨Geminiåˆ†æè¡¥å……ææ–™     â”‚ â€¢ Gemini Visionåˆ†ææ¯å¼ å›¾    â”‚
â”‚ â€¢ æå–è´Ÿé¢ç»“æœ:             â”‚ â€¢ æ£€æµ‹:                      â”‚
â”‚   - på€¼>0.05 (ä¸æ˜¾è‘—)       â”‚   - Western Blotæ‹¼æ¥         â”‚
â”‚   - "Data not shown"        â”‚   - æ•°æ®ç‚¹å…‹éš†               â”‚
â”‚   - å—è¯•è€…é€€å‡º               â”‚   - è¯¯å·®æ¡å¼‚å¸¸               â”‚
â”‚                             â”‚                              â”‚
â”‚ OUTPUT:                     â”‚ OUTPUT:                      â”‚
â”‚   - text_evidence: List     â”‚   - forensic_evidence: List  â”‚
â”‚   - compiled_evidence_text  â”‚   - suspicious_images: List  â”‚
â”‚   - failed_files: List      â”‚   - forensic_failed_files    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NODE 3: GRAPH BUILDER (å¯é€‰)                      â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚ â€¢ æ•°æ®éªŒè¯ (StreamValidator)                      â”‚
â”‚ â€¢ Neo4jçŸ¥è¯†å›¾è°±æ„å»º                               â”‚
â”‚ â€¢ å¤±è´¥æ–‡ä»¶è¿½è¸ª                                    â”‚
â”‚                                                   â”‚
â”‚ OUTPUT:                                           â”‚
â”‚   - validated_data: Dict                          â”‚
â”‚   - failed_count: int                             â”‚
â”‚   - confidence_score: float (åŸºäºå†…å®¹è´¨é‡)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NODE 4: WRITER (src/agents/report_writer.py)     â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚ â€¢ èšåˆä¸‰å¼•æ“æ•°æ®                                   â”‚
â”‚ â€¢ Geminiç»¼åˆåˆ†æ (é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›)                    â”‚
â”‚ â€¢ é£é™©è¯„åˆ†è®¡ç®—                                     â”‚
â”‚ â€¢ Markdownæ¨¡æ¿æ¸²æŸ“                                â”‚
â”‚ â€¢ PDFå¯¼å‡º (wkhtmltopdf)                           â”‚
â”‚                                                   â”‚
â”‚ OUTPUT:                                           â”‚
â”‚   - markdown_content: str                         â”‚
â”‚   - markdown_path: Path                           â”‚
â”‚   - pdf_path: Path                                â”‚
â”‚   - recommendation: str                           â”‚
â”‚   - confidence_score: float                       â”‚
â”‚   - risk_score: float                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
æœ€ç»ˆæŠ¥å‘Šè¾“å‡ºåˆ° final_reports/
```

### 2.2 å…³é”®æµç¨‹èŠ‚ç‚¹è¯¦è§£

#### Node 1: Harvester (æ•°æ®é‡‡é›†)
**æ–‡ä»¶**: `BioHarvestEngine/agent.py`

**æ ¸å¿ƒé€»è¾‘**:
```python
def run(user_query: str) -> Dict:
    # STEP A: LLMç”Ÿæˆæœç´¢æŸ¥è¯¢
    queries = self._generate_search_queries(user_query)
    # ä¾‹å¦‚: "CRISPR off-target" â†’ 
    #   ["CRISPR off-target effects clinical trial",
    #    "CRISPR safety terminated trials",
    #    "Cas9 adverse events"]
    
    # STEP B: å¹¶è¡Œæœç´¢
    with ThreadPoolExecutor() as executor:
        europmc_results = executor.submit(europmc.search, queries)
        pubmed_results = executor.submit(search_pubmed, queries)
        trial_results = executor.submit(search_failed_trials, queries)
    
    # STEP C: PDFä¸‹è½½ (ä»…EuroPMCæä¾›ç›´æ¥ä¸‹è½½)
    for paper in europmc_results:
        if paper['has_pdf']:
            local_path = download_pdf_from_url(
                paper['pdf_url'], 
                dest_dir='downloads/pmc_pdfs/'
            )
            paper['local_path'] = local_path
    
    return {
        'results': [...],
        'pdf_paths': [local_paths]
    }
```

**å…³é”®æ•°æ®ç»“æ„**:
```json
{
  "results": [
    {
      "title": "CRISPR-Cas9 off-target effects...",
      "source": "PMC",
      "link": "https://europmc.org/article/PMC/PMC12345678",
      "local_path": "F:/VSCode/Cassandra/downloads/pmc_pdfs/PMC12345678.pdf",
      "status": "Published",
      "date": "2025-01-15"
    },
    {
      "title": "EDIT-101 Trial",
      "source": "ClinicalTrials.gov",
      "status": "TERMINATED",
      "why_stopped": "Sponsor decision",
      "nct_id": "NCT03872479"
    }
  ]
}
```

#### Node 2A: Miner (æš—æ•°æ®æŒ–æ˜)
**æ–‡ä»¶**: `EvidenceEngine/agent.py`

**æ ¸å¿ƒé€»è¾‘**:
```python
def analyze_pdf(pdf_path: str) -> List[RiskEvidence]:
    # STEP 1: æå–æ–‡æœ¬ (ä¼˜å…ˆçº§: PyMuPDF > PDFMiner > OCR)
    full_text = extract_text_from_pdf(pdf_path)
    
    # STEP 2: Geminiåˆ†æ (2M token context!)
    prompt = f"""
    Analyze this PDF for buried negative results:
    - p-values > 0.05 in supplementary tables
    - "Data not shown" mentions
    - Subject dropouts without explanation
    
    PDF Content:
    {full_text[:500000]}  # å¯ä»¥æ”¾å·¨å¤§çš„ä¸Šä¸‹æ–‡
    """
    
    findings = llm.generate(prompt)
    
    # STEP 3: ç»“æ„åŒ–è¾“å‡º
    return [
        RiskEvidence(
            source="PMC12345678.pdf",
            page_estimate=15,
            quote="Table S3: p=0.47 (not significant)",
            risk_level="HIGH",
            risk_type="statistical_insignificance",
            explanation="Efficacy endpoint failed statistical threshold"
        )
    ]
```

**å…³é”®è¾“å‡º**:
```python
{
    "text_evidence": [...],  # ç»“æ„åŒ–é£é™©åˆ—è¡¨
    "compiled_evidence_text": "=== EVIDENCE SOURCE: file1.pdf ===\n...",  # å¯Œæ–‡æœ¬æ‘˜è¦
    "failed_files": ["corrupted.pdf"],
    "total_files": 27
}
```

#### Node 2B: Auditor (å›¾åƒå–è¯)
**æ–‡ä»¶**: `ForensicEngine/agent.py`

**æ ¸å¿ƒé€»è¾‘**:
```python
def audit_images(pdf_path: str) -> List[ImageAuditResult]:
    # STEP 1: æå–æ‰€æœ‰å›¾åƒ
    images = extract_images_from_pdf(pdf_path)  # PyMuPDF
    
    # STEP 2: è¿‡æ»¤å°å›¾æ ‡ (åªä¿ç•™ç§‘å­¦å›¾è¡¨)
    figures = [img for img in images if img.width > 200 and img.height > 200]
    
    # STEP 3: Gemini Visionåˆ†æ
    for fig in figures:
        analysis = gemini_vision.analyze_image(
            image=fig.bytes,
            prompt=FORENSIC_ANALYSIS_PROMPT
        )
        
        # æ£€æµ‹: Western Blotæ‹¼æ¥, æ•°æ®ç‚¹å…‹éš†, è¯¯å·®æ¡å¼‚å¸¸
        if analysis['tampering_risk_score'] > 0.7:
            suspicious_images.append(ImageAuditResult(...))
    
    return suspicious_images
```

#### Node 4: Writer (æŠ¥å‘Šåˆæˆ)
**æ–‡ä»¶**: `src/agents/report_writer.py`

**æ ¸å¿ƒæµç¨‹**:
```python
def generate_report(harvest, forensic, evidence):
    # STEP A: æ•°æ®èšåˆ
    report_data = ReportData(
        harvest_results=harvest,
        forensic_results=forensic,
        evidence_results=evidence
    )
    
    # STEP B: Geminiç»¼åˆåˆ†æ (é•¿ä¸Šä¸‹æ–‡!)
    evidence_summary = self._prepare_evidence_summary(report_data)
    # å°†æ‰€æœ‰ä¸‰å¼•æ“çš„æ•°æ®æ‰“åŒ…æˆä¸€ä¸ªå·¨å¤§çš„prompt
    
    synthesized = llm.generate(f"""
    Based on this evidence:
    {evidence_summary}  # å¯èƒ½æ˜¯100K+ tokens
    
    Write:
    - Executive Summary
    - Bull/Bear/Black Swan Cases
    - Risk Cascade Analysis
    """)
    
    # STEP C: é£é™©è¯„åˆ†
    risk_score = self._calculate_risk_scores(report_data)
    
    # STEP D: æ¨¡æ¿æ¸²æŸ“
    markdown = template.render({
        'project_name': '...',
        'executive_summary_text': synthesized['executive_summary'],
        'risk_score': risk_score,
        # ... 100+ å˜é‡
    })
    
    # STEP E: PDFè½¬æ¢
    pdf_path = convert_markdown_to_pdf(markdown)
    
    return ReportOutput(...)
```

---

## 3. æ•°æ®æµåˆ†æ

### 3.1 æ•°æ®æµå›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Query      â”‚
â”‚ "Evaluate       â”‚
â”‚ CRISPR          â”‚
â”‚ off-target"     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AgentState (LangGraph State Container)  â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ {                                       â”‚
â”‚   "user_query": str,                    â”‚
â”‚   "harvested_data": List[Dict],         â”‚
â”‚   "pdf_paths": List[str],               â”‚
â”‚   "text_evidence": List[RiskEvidence],  â”‚
â”‚   "forensic_evidence": List[ImageAudit],â”‚
â”‚   "compiled_evidence_text": str,        â”‚
â”‚   "failed_files": List[str],            â”‚
â”‚   "confidence_score": float,            â”‚
â”‚   "risk_override": Optional[str]        â”‚
â”‚ }                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                  â”‚
         â†“                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HARVESTED DATA   â”‚            â”‚ PDF FILES        â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚            â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚ â€¢ 117 trials     â”‚            â”‚ â€¢ 27 PDFs found  â”‚
â”‚ â€¢ 60 failed      â”‚            â”‚ â€¢ 3 downloaded   â”‚
â”‚ â€¢ Metadata:      â”‚            â”‚ â€¢ 24 FAILED      â”‚
â”‚   - NCT IDs      â”‚            â”‚                  â”‚
â”‚   - Status       â”‚            â”‚ Location:        â”‚
â”‚   - Why stopped  â”‚            â”‚ downloads/       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ pmc_pdfs/        â”‚
         â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                â”‚
         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚    â”‚
         â†“    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EVIDENCE EXTRACTION (Parallel)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Text Evidence     â”‚ Image Evidence    â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚ â€¢ 38 items found  â”‚ â€¢ 10 images       â”‚
â”‚ â€¢ 0 HIGH risk     â”‚ â€¢ 0 suspicious    â”‚
â”‚ â€¢ 24 failed PDFs  â”‚                   â”‚
â”‚                   â”‚                   â”‚
â”‚ Example:          â”‚ Example:          â”‚
â”‚ {                 â”‚ {                 â”‚
â”‚   "quote": "...", â”‚   "image_id": "3",â”‚
â”‚   "risk_level":   â”‚   "status": "OK", â”‚
â”‚     "MEDIUM",     â”‚   "score": 0.2    â”‚
â”‚   "page": 15      â”‚ }                 â”‚
â”‚ }                 â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STREAMVALIDATOR CHECKPOINT              â”‚
â”‚ (src/utils/stream_validator.py)        â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ â€¢ éªŒè¯JSONç»“æ„                          â”‚
â”‚ â€¢ å¡«å……ç¼ºå¤±å­—æ®µä¸ºé»˜è®¤å€¼                   â”‚
â”‚ â€¢ è®¡ç®—confidence_score:                 â”‚
â”‚   confidence = (valid_files/total) * 10 â”‚
â”‚   = (3/27) * 10 = 1.1 â†’ Final: 2.1     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ REPORT SYNTHESIS (Gemini Long Context)  â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ INPUT VARIABLES:                        â”‚
â”‚ â€¢ compiled_evidence_text: 5K chars      â”‚
â”‚ â€¢ failed_count: 24                      â”‚
â”‚ â€¢ total_files: 27                       â”‚
â”‚ â€¢ risk_override: "UNCERTAIN"            â”‚
â”‚                                         â”‚
â”‚ LLM PROMPT (ç®€åŒ–):                       â”‚
â”‚ """                                     â”‚
â”‚ CRITICAL WARNING:                       â”‚
â”‚ - 24/27 PDFs FAILED                     â”‚
â”‚ - confidence_score: 2.1/10              â”‚
â”‚ - You MUST state "Data not available"   â”‚
â”‚   for sections without evidence         â”‚
â”‚ - DO NOT invent data                    â”‚
â”‚                                         â”‚
â”‚ Evidence:                               â”‚
â”‚ {compiled_evidence_text}                â”‚
â”‚                                         â”‚
â”‚ Generate:                               â”‚
â”‚ - executive_summary                     â”‚
â”‚ - bull_case, bear_case                  â”‚
â”‚ - compound_name, moa_description        â”‚
â”‚ """                                     â”‚
â”‚                                         â”‚
â”‚ LLM OUTPUT (JSON):                      â”‚
â”‚ {                                       â”‚
â”‚   "executive_summary": "...high risk...",â”‚
â”‚   "bull_case": "The 43% responder...",  â”‚
â”‚   "compound_name": "[Data not available]",â”‚
â”‚   "probability_bull": "[Data not...]"   â”‚
â”‚ }                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TEMPLATE RENDERING                      â”‚
â”‚ (src/templates/biomedical_report.md)   â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ â€¢ æ›¿æ¢ {{variable}} ä¸ºå®é™…å€¼            â”‚
â”‚ â€¢ åŠ¨æ€æ¸²æŸ“ {{#each failed_trials}}      â”‚
â”‚ â€¢ æœªæ¸²æŸ“çš„å˜é‡ â†’ "[Data not available]" â”‚
â”‚                                         â”‚
â”‚ Example:                                â”‚
â”‚ {{compound_name}}                       â”‚
â”‚   â†“ (from synthesized)                  â”‚
â”‚ [Data not available]                    â”‚
â”‚                                         â”‚
â”‚ {{bull_case}}                           â”‚
â”‚   â†“ (from synthesized)                  â”‚
â”‚ The 'meaningful improvements'...        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FINAL REPORT                            â”‚
â”‚ (final_reports/evaluate_crispr_...md)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 å…³é”®æ•°æ®ç»“æ„

#### AgentState (LangGraph State)
```python
# å®šä¹‰: src/graph/state.py
class AgentState(TypedDict):
    user_query: str
    harvested_data: List[Dict[str, Any]]
    pdf_paths: List[str]  # æœ¬åœ°PDFè·¯å¾„åˆ—è¡¨
    text_evidence: List[Dict]  # EvidenceEngineè¾“å‡º
    forensic_evidence: List[Dict]  # ForensicEngineè¾“å‡º
    compiled_evidence_text: str  # å¯Œæ–‡æœ¬æ ¼å¼çš„è¯æ®æ‘˜è¦
    failed_files: List[str]  # å¤±è´¥çš„PDFæ–‡ä»¶å
    total_files: int  # å°è¯•å¤„ç†çš„æ€»æ–‡ä»¶æ•°
    confidence_score: float  # 0-10, åŸºäºæ•°æ®è´¨é‡
    risk_override: Optional[str]  # "UNCERTAIN", "HIGH" ç­‰
    status: str  # "harvest_complete", "analysis_complete" ç­‰
```

#### RiskEvidence (EvidenceEngine Output)
```python
# å®šä¹‰: EvidenceEngine/agent.py
@dataclass
class RiskEvidence:
    source: str  # æ–‡ä»¶åæˆ–PMC ID
    page_estimate: int  # é¡µç ä¼°è®¡
    quote: str  # åŸæ–‡å¼•ç”¨
    risk_level: str  # "HIGH", "MEDIUM", "LOW"
    risk_type: str  # "statistical_insignificance", "dropout", etc.
    explanation: str  # é£é™©è§£é‡Š
```

#### ImageAuditResult (ForensicEngine Output)
```python
# å®šä¹‰: ForensicEngine/agent.py
@dataclass
class ImageAuditResult:
    image_id: str
    image_path: str
    page_num: int
    status: str  # "CLEAN", "SUSPICIOUS", "ERROR"
    tampering_risk_score: Optional[float]  # 0.0-1.0
    findings: str
    raw_analysis: str
```

---

## 4. Final Report ç»„æˆè§£æ

### 4.1 æŠ¥å‘Šæ¨¡æ¿ç»“æ„
**æ¨¡æ¿æ–‡ä»¶**: `src/templates/biomedical_report.md`

```markdown
# {{project_name}} - Biomedical Due Diligence Report

## Executive Summary
**Investment Recommendation:** {{recommendation}}
**Confidence Score:** {{confidence_score}}/10
**Risk Level:** {{risk_level}}

{{executive_summary_text}}

**Red Flags:** {{red_flags_list}}
**Decision Factors:** {{decision_factors}}

## 1. Project Overview
**Compound Name:** {{compound_name}}
**MoA:** {{moa_description}}
**Target:** {{target_description}}
**Stage:** {{development_stage}}
**Sponsor:** {{sponsor_company}}

## 2. Clinical Trial Audit
**Total Trials:** {{total_trials}}
**Failed:** {{failed_trials_count}}
**Success Rate:** {{success_rate}}%

{{#each failed_trials}}
  #### Trial {{@index}}: {{this.nct_id}}
  **Status:** {{this.status}}
  **Why Stopped:** {{this.why_stopped}}
{{/each}}

## 3. Dark Data Mining
**PDFs Analyzed:** {{pdfs_analyzed_count}}
**Risk Signals:** {{total_evidence_items}}
**High-Risk:** {{high_risk_count}}

{{#each high_risk_evidence}}
  **Quote:** {{this.quote}}
  **Risk:** {{this.risk_level}}
{{/each}}

## 4. Forensic Image Audit
**Images Analyzed:** {{total_images_analyzed}}
**Suspicious:** {{suspicious_images_count}}

## 5. Risk Graveyard
{{failure_timeline}}
{{risk_cascade_narrative}}

## 6. Evidence Synthesis
**Bull Case:** {{bull_case}}
**Bear Case:** {{bear_case}}
**Black Swan:** {{black_swan_case}}
**Verdict:** {{analyst_verdict}}

## 7. Conclusion
**Decision:** {{recommendation}}
**Rationale:** [Usually synthesized text]
```

### 4.2 æ•°æ®æ¥æºæ˜ å°„è¡¨

| æŠ¥å‘Šéƒ¨åˆ† | å˜é‡å | æ•°æ®æ¥æº | è®¡ç®—/åˆæˆæ–¹å¼ |
|---------|-------|---------|--------------|
| **Header** | `project_name` | æ‰‹åŠ¨è¾“å…¥ æˆ– ä»queryæå– | - |
| | `report_date` | ç³»ç»Ÿæ—¶é—´ | `datetime.now()` |
| | `user_query` | ç”¨æˆ·è¾“å…¥ | ç›´æ¥ä¼ é€’ |
| **Executive Summary** | `recommendation` | é£é™©è®¡ç®— | åŸºäº `total_risk_score` <br> â‰¥7="AVOID", 4-7="CAUTION", <4="CONSIDER" |
| | `confidence_score` | æ•°æ®è´¨é‡è¯„ä¼° | `(valid_files/total_files) * 10` <br> **å½“å‰å€¼: 2.1** |
| | `risk_level` | é£é™©è¦†ç›–é€»è¾‘ | `risk_override` OR è®¡ç®—å€¼ <br> **å½“å‰: "LOW" (çŸ›ç›¾)** |
| | `executive_summary_text` | **LLMç»¼åˆ** | GeminiåŸºäºå…¨éƒ¨è¯æ®ç”Ÿæˆ <br> **æœ‰å†…å®¹** |
| | `red_flags_list` | **LLMç»¼åˆ** | Geminiæå–å…³é”®é£é™©ç‚¹ <br> **æœ‰å†…å®¹** |
| | `decision_factors` | **LLMç»¼åˆ** | Geminiç”Ÿæˆå†³ç­–å…³é”®é—®é¢˜ <br> **æœ‰å†…å®¹** |
| **Project Overview** | `compound_name` | **LLMæå–** | ä»æ–‡çŒ®ä¸­è¯†åˆ«è¯ç‰©å <br> **å½“å‰: [Data not available]** âŒ |
| | `moa_description` | **LLMæå–** | ä»æ–‡çŒ®ä¸­æå–ä½œç”¨æœºåˆ¶ <br> **å½“å‰: [Data not available]** âŒ |
| | `target_description` | **LLMæå–** | è¯†åˆ«åˆ†å­é¶ç‚¹ <br> **å½“å‰: [Data not available]** âŒ |
| | `development_stage` | **LLMæå–** | ä»è¯•éªŒæ•°æ®æ¨æ–­é˜¶æ®µ <br> **å½“å‰: [Data not available]** âŒ |
| | `sponsor_company` | **LLMæå–** | ä»è¯•éªŒå…ƒæ•°æ®æå– <br> **å½“å‰: [Data not available]** âŒ |
| | `market_context` | **LLMç»¼åˆ** | ç«äº‰æ ¼å±€åˆ†æ <br> **å½“å‰: [Data not available]** âŒ |
| | `scientific_rationale` | **LLMç»¼åˆ** | ç§‘å­¦åˆç†æ€§åˆ†æ <br> **æœ‰å†…å®¹** |
| **Clinical Trials** | `total_trials` | BioHarvestEngine | ç›´æ¥è®¡æ•° `len(harvest_results)` <br> **å½“å‰: 117** |
| | `failed_trials_count` | BioHarvestEngine | è¿‡æ»¤ `status in ['TERMINATED', 'SUSPENDED']` <br> **å½“å‰: 60** |
| | `success_rate` | è®¡ç®— | `(total - failed) / total * 100` <br> **å½“å‰: 48.7%** |
| | `failed_trials` åˆ—è¡¨ | BioHarvestEngine | æ¯ä¸ªè¯•éªŒçš„è¯¦ç»†ä¿¡æ¯ <br> **éƒ¨åˆ†æ¸²æŸ“** (Trial 1-5) |
| **Dark Data** | `pdfs_analyzed_count` | EvidenceEngine | `len(evidence_results)` <br> **å½“å‰: 38** |
| | `total_evidence_items` | EvidenceEngine | é£é™©ä¿¡å·æ€»æ•° <br> **å½“å‰: 38** |
| | `high_risk_count` | EvidenceEngine | è¿‡æ»¤ `risk_level == 'HIGH'` <br> **å½“å‰: 0** |
| | `high_risk_evidence` åˆ—è¡¨ | EvidenceEngine | é«˜é£é™©è¯æ®è¯¦æƒ… <br> **å½“å‰: æ— ** |
| **Forensic Audit** | `total_images_analyzed` | ForensicEngine | `len(forensic_results)` <br> **å½“å‰: 10** |
| | `suspicious_images_count` | ForensicEngine | è¿‡æ»¤ `status == 'suspicious'` <br> **å½“å‰: 0** |
| | `suspicious_images` åˆ—è¡¨ | ForensicEngine | å¯ç–‘å›¾åƒè¯¦æƒ… <br> **å½“å‰: æ— ** |
| | `western_blot_count` | ForensicEngine | å›¾åƒç±»å‹ç»Ÿè®¡ <br> **å½“å‰: 3** |
| | `microscopy_count` | ForensicEngine | æ˜¾å¾®é•œå›¾åƒç»Ÿè®¡ <br> **å½“å‰: 3** |
| | `chart_count` | ForensicEngine | å›¾è¡¨ç»Ÿè®¡ <br> **å½“å‰: 3** |
| **Risk Scores** | `clinical_failure_score` | è®¡ç®— | `(failed_trials/total_trials) * 10` <br> **å½“å‰: 10.0** |
| | `dark_data_score` | è®¡ç®— | `(high_risk_count/total_evidence) * 10` <br> **å½“å‰: 0.0** |
| | `forensic_score` | è®¡ç®— | `(suspicious/total_images) * 10` <br> **å½“å‰: 0.0** |
| | `literature_score` | **LLMè¯„ä¼°** | åŸºäºæ–‡çŒ®è´¨é‡æ‰“åˆ† <br> **å½“å‰: 5.0** |
| | `total_risk_score` | åŠ æƒå¹³å‡ | `Î£(score * weight)` <br> **å½“å‰: 3.8** |
| **Investment Thesis** | `bull_case` | **LLMç»¼åˆ** | æœ€ä½³æƒ…å†µåˆ†æ <br> **æœ‰å†…å®¹** |
| | `bear_case` | **LLMç»¼åˆ** | åŸºå‡†æƒ…å†µåˆ†æ <br> **æœ‰å†…å®¹** |
| | `black_swan_case` | **LLMç»¼åˆ** | æœ€åæƒ…å†µåˆ†æ <br> **æœ‰å†…å®¹** |
| | `analyst_verdict` | **LLMç»¼åˆ** | åˆ†æå¸ˆåˆ¤æ–­ <br> **æœ‰å†…å®¹** |
| | æ¦‚ç‡æƒé‡ | **LLMç»¼åˆ** | Bull/Bear/Black Swanæ¦‚ç‡ <br> **å½“å‰: [Data not available]** âŒ |
| **Conclusion** | `final_recommendation` | **LLMç»¼åˆ** | æœ€ç»ˆå†³ç­– <br> **å½“å‰: [Data not available]** âŒ |
| | `rationale` | **LLMç»¼åˆ** | å†³ç­–ç†ç”± <br> **å½“å‰: [Data not available]** âŒ |

### 4.3 æŠ¥å‘Šç”Ÿæˆæµç¨‹

```python
# ä¼ªä»£ç : src/agents/report_writer.py

def generate_report():
    # STEP A: æ•°æ®èšåˆ
    report_data = {
        'harvest_results': { 'results': [...117 trials...] },
        'forensic_results': [...10 images...],
        'evidence_results': [...38 risk items...]
    }
    
    # STEP B: å‡†å¤‡è¯æ®æ‘˜è¦ (ä¼ ç»™LLMçš„è¶…é•¿prompt)
    evidence_summary = f"""
    === HARVESTED DATA ===
    â€¢ 117 trials found
    â€¢ 60 failed trials:
      - NCT01234567: TERMINATED (sponsor decision)
      - NCT... (ç»§ç»­åˆ—ä¸¾)
    
    === EVIDENCE EXTRACTED ===
    â€¢ PDF 1: PMC12345678.pdf
      - Finding 1: "p=0.47, not significant" (Page 15)
      - Finding 2: "8 patients withdrew" (Page 22)
    â€¢ PDF 2: ...
    
    === FORENSIC FINDINGS ===
    â€¢ Image 1: Western Blot (Page 8)
      - Status: CLEAN
      - Score: 0.2 (low risk)
    
    === DATA QUALITY WARNING ===
    â€¢ 24 out of 27 PDFs FAILED to process
    â€¢ Confidence Score: 2.1/10
    â€¢ Analysis Status: CRITICAL_FAILURE
    """
    
    # STEP C: LLMç»¼åˆ (Gemini Long Context)
    synthesis_prompt = f"""
    {SYSTEM_PROMPT}  # è§report_writer.py line 150
    
    **CRITICAL WARNING:**
    - 24/27 PDFs failed â†’ confidence_score = 2.1/10
    - You MUST state "[Data not available]" for ANY section
      where evidence is insufficient
    - DO NOT invent data or use general knowledge
    
    Evidence Summary:
    {evidence_summary}  # å¯èƒ½5K-500K tokens
    
    Generate JSON:
    {{
      "executive_summary": "...",
      "compound_name": "...",  # â† å¦‚æœæ‰¾ä¸åˆ°,å¿…é¡»è¿”å› null
      "moa_description": "...",
      "bull_case": "...",
      "probability_bull": "..."  # â† å¦‚æœæ²¡æ•°æ®,å¿…é¡»è¿”å› null
    }}
    """
    
    synthesized = llm.generate(synthesis_prompt)
    # å®é™…è¿”å› (å½“å‰CRISPRæŠ¥å‘Š):
    # {
    #   "executive_summary": "The clinical viability...",  âœ…
    #   "compound_name": null,  â† LLMæ­£ç¡®è¿”å›null
    #   "moa_description": null,
    #   "bull_case": "The 'meaningful improvements'...",  âœ…
    #   "probability_bull": null  â† LLMæ­£ç¡®è¿”å›null
    # }
    
    # STEP D: å¡«å……é»˜è®¤å€¼ (é˜²æ­¢KeyError)
    synthesized_sections = {
        'executive_summary': synthesized.get('executive_summary', ''),
        'compound_name': synthesized.get('compound_name') or '[Data not available]',  # â† è¿™é‡Œè½¬æ¢
        'moa_description': synthesized.get('moa_description') or '[Data not available]',
        'bull_case': synthesized.get('bull_case', ''),
        'probability_bull': synthesized.get('probability_bull') or '[Data not available]'
    }
    
    # STEP E: æ¨¡æ¿æ¸²æŸ“
    template_vars = {
        'project_name': 'Evaluate CRISPR off-target',
        'confidence_score': '6.0',  # â† æ³¨æ„: è¿™é‡Œæ˜¯overrideåçš„å€¼
        'risk_level': 'LOW',  # â† æ³¨æ„: çŸ›ç›¾çš„é£é™©ç­‰çº§
        **synthesized_sections  # å±•å¼€æ‰€æœ‰LLMç”Ÿæˆçš„å†…å®¹
    }
    
    markdown = template.replace('{{compound_name}}', template_vars['compound_name'])
    # â†’ markdownä¸­åŒ…å« "[Data not available]"
    
    return markdown
```

---

## 5. "Data not available" æ ¹å› åˆ†æ

### 5.1 é—®é¢˜è¯Šæ–­

åœ¨å½“å‰æŠ¥å‘Š (`evaluate_crispr_off-target_20260208_234548.md`) ä¸­ï¼Œæœ‰ **13å¤„** "[Data not available]"ï¼š

| ä½ç½® | å˜é‡ | æœŸæœ›å€¼ | å®é™…çŠ¶æ€ |
|-----|------|-------|---------|
| Line 267 | `probability_bull` | æ¦‚ç‡ç™¾åˆ†æ¯” | `[Data not available]` |
| Line 268 | `probability_bear` | æ¦‚ç‡ç™¾åˆ†æ¯” | `[Data not available]` |
| Line 269 | `probability_black_swan` | æ¦‚ç‡ç™¾åˆ†æ¯” | `[Data not available]` |
| Line 271 | `expected_outcome` | æœŸæœ›ç»“æœ | `[Data not available]` |
| Line 279 | `final_recommendation` | æœ€ç»ˆå†³ç­– | `[Data not available]` |
| Line 282 | `rationale` | å†³ç­–ç†ç”± | `[Data not available]` |
| Section 6 | `detailed_analysis` | è¯¦ç»†åˆ†æ | `[Data not available]` (å¤šå¤„) |
| Section 7 | `risk_mitigation_strategies` | é£é™©ç¼“è§£ç­–ç•¥ | `[Data not available]` |
| Section 7 | `key_questions_for_management` | ç®¡ç†å±‚é—®é¢˜ | `[Data not available]` |
| Section 7 | `monitoring_triggers` | ç›‘æ§è§¦å‘å™¨ | `[Data not available]` |

### 5.2 æ ¹å› åˆ†æ (Root Cause Analysis)

#### ğŸ” ç›´æ¥åŸå› 
LLM (Gemini) åœ¨ç»¼åˆåˆ†æé˜¶æ®µ **æœªç”Ÿæˆ** è¿™äº›å­—æ®µçš„å†…å®¹ï¼Œè€Œæ˜¯è¿”å› `null` æˆ–å®Œå…¨çœç•¥ã€‚

#### ğŸ” æ·±å±‚åŸå› 

**1. æ•°æ®è´¨é‡ä¸¥é‡ä¸è¶³**
```python
# supervisor.py, line 250
valid_sources = 3  # åªæœ‰3ä¸ªPDFæˆåŠŸæå–
total_files = 27
confidence_score = (3 / 27) * 10 = 1.1

# æ•°æ®å®Œæ•´æ€§: 11%
# â†’ ä¸¥é‡ä½äºæœ€ä½é˜ˆå€¼ (é€šå¸¸éœ€è¦ >50%)
```

**2. LLM System Prompt çš„ä¸¥æ ¼çº¦æŸ** âš ï¸
```python
# report_writer.py, line 450-470
synthesis_prompt = f"""
**CRITICAL WARNING:**
- 24/27 PDFs failed
- confidence_score: 2.1/10
- You MUST state "[Data not available]" for sections without evidence
- DO NOT invent data
- If uncertain, return null instead of guessing

**PROHIBITED:**
- âŒ "Studies suggest..." (vague)
- âŒ Using general biomedical knowledge
- âœ… ONLY use evidence explicitly provided above
"""
```

**ğŸ“Œ åˆ†æ**: è¿™æ®µprompt **æ˜¯ä¸»è¦åŸå› ä¹‹ä¸€ï¼Œä½†ä¸æ˜¯å”¯ä¸€åŸå› **ã€‚å®ƒæ˜¯ä¸€ç§"è¯šå®ä½†ä¸¥æ ¼"çš„è®¾è®¡é€‰æ‹©ï¼š
- âœ… **å¥½å¤„**: é˜²æ­¢LLMç¼–é€ æ•°æ®ï¼Œç¡®ä¿æŠ¥å‘Šçš„ç§‘å­¦ä¸¥è°¨æ€§
- âŒ **ä»£ä»·**: å½“æ•°æ®ä¸è¶³æ—¶ï¼ŒLLMä¼šå¤§é‡è¿”å›nullï¼Œå¯¼è‡´"[Data not available]"
- ğŸ” **æƒè¡¡**: å¦‚æœç§»é™¤è¿™ä¸ªçº¦æŸï¼ŒLLMå¯èƒ½ä¼šåŸºäºé€šç”¨çŸ¥è¯†å¡«å……å†…å®¹ï¼Œä½†ä¼šé™ä½æŠ¥å‘Šçš„å¯ä¿¡åº¦

**æ ¹æœ¬é—®é¢˜ä»ç„¶æ˜¯PDFæå–å¤±è´¥ç‡è¿‡é«˜**ï¼Œå³ä½¿æ”¾æ¾promptçº¦æŸï¼Œå¦‚æœåªæœ‰3ä¸ªæœ‰æ•ˆPDFï¼Œæ·±åº¦åˆ†æå­—æ®µä¾ç„¶æ— æ³•ç”Ÿæˆã€‚

**3. æ¨¡æ¿å¡«å……çš„åå¤‡æœºåˆ¶**
```python
# report_writer.py, line 890-898
template_vars = {
    'compound_name': synthesized.get('compound_name') or '[Data not available]',
    'moa_description': synthesized.get('moa_description') or '[Data not available]',
    'probability_bull': synthesized.get('probability_bull') or '[Data not available]',
    # ... å…¶ä»–å­—æ®µåŒç†
}
```

**4. PDFä¸‹è½½/æå–å¤±è´¥çš„æ ¹æœ¬é—®é¢˜** ğŸ”

```python
# supervisor.py, miner_node, line 180-250
failed_files = []  # å¤±è´¥æ–‡ä»¶åˆ—è¡¨
for pdf_path in state.get("pdf_paths", []):
    try:
        full_text = extract_text_from_pdf(pdf_path)
        if len(full_text) < 100:  # å†…å®¹å¤ªå°‘
            raise ValueError("Insufficient content")
        # ... æå–é€»è¾‘
    except Exception as e:
        failed_files.append(pdf_path)
        logger.error(f"PDF extraction failed: {e}")

# ç»“æœ: 24/27 PDFså¤±è´¥
```

**æ·±åº¦åˆ†æ: ä¸‰ä¸ªç»´åº¦çš„å¤±è´¥**

**ç»´åº¦1: PDFä¸‹è½½é—®é¢˜** (src/tools/pdf_downloader.py)
```python
# ä¸‹è½½å™¨å·²å®ç°ç¼“å­˜æœºåˆ¶
if file_path.exists() and file_path.stat().st_size > 5000:  # >5KB
    logger.info(f"âš¡ PDF cached: {file_path}")
    return str(file_path.absolute())

# é—®é¢˜: 
# âœ… ç¼“å­˜é€»è¾‘æ­£å¸¸å·¥ä½œ - å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ä¸”>5KB,ç›´æ¥è¿”å›è·¯å¾„
# âŒ ä½†URLå¤±æ•ˆæ—¶ä¼šé™é»˜å¤±è´¥ - 24ä¸ªPDFå¯èƒ½æ ¹æœ¬æ²¡ä¸‹è½½æˆåŠŸ
# âŒ Europe PMC 403é”™è¯¯ - TLSæŒ‡çº¹è¯†åˆ«è¢«ç»•è¿‡ä½†ä»å¯èƒ½è¢«é™æµ
```

**å¯èƒ½çš„ä¸‹è½½å¤±è´¥åŸå› **:
1. **URLå¤±æ•ˆ**: EuroPMCçš„PMC IDåœ¨å½“å‰æ•°æ®åº“ä¸­ä¸å­˜åœ¨(404)
2. **APIé™æµ**: çŸ­æ—¶é—´å†…27ä¸ªè¯·æ±‚è§¦å‘rate limit(403)
3. **ç½‘ç»œè¶…æ—¶**: å¤§æ–‡ä»¶ä¸‹è½½è¶…è¿‡120s timeout
4. **é‡å®šå‘é—®é¢˜**: PDFé“¾æ¥æŒ‡å‘é”™è¯¯çš„èµ„æº

**ç»´åº¦2: PDFæå–é—®é¢˜** (src/tools/pdf_processor.py)
```python
# å½“å‰æå–é€»è¾‘
def extract_text_from_pdf(pdf_path: str) -> str:
    pdf_document = fitz.open(pdf_path)
    
    # âœ… å·²æ£€æµ‹åŠ å¯†PDF
    if pdf_document.is_encrypted:
        raise ValueError("ENCRYPTED_PDF: Password-protected")
    
    # âœ… å·²æ£€æµ‹æ‰«æç‰ˆPDF
    if pages_without_text == total_pages:
        raise ValueError("SCANNED_PDF: All pages are images")
    
    # âŒ ä½†æ²¡æœ‰OCR fallback!
```

**å½“å‰çŠ¶æ€**: **éƒ¨åˆ†æ£€æµ‹,æ— è‡ªåŠ¨ä¿®å¤**
- âœ… èƒ½è¯†åˆ« ENCRYPTED_PDF, SCANNED_PDF, CORRUPTED_PDF
- âŒ é‡åˆ°æ‰«æç‰ˆPDFæ—¶ç›´æ¥æŠ›å‡ºé”™è¯¯,æ²¡æœ‰è°ƒç”¨Gemini Vision OCR
- âŒ æ²¡æœ‰PDFMiner fallback (PyMuPDFå¤±è´¥æ—¶çš„å¤‡é€‰æ–¹æ¡ˆ)

**ç»´åº¦3: æ•°æ®ä¼ è¾“æ ¼å¼ä¸€è‡´æ€§** (EvidenceEngine/agent.py)
```python
# è¿”å›æ ¼å¼ä¸¥æ ¼æ£€æŸ¥
return {
    "paper_summary": "Error: ...",
    "risk_signals": [],
    "filename": Path(pdf_path).name,
    "error_type": "SCANNED_PDF",  # â† é”™è¯¯ç±»å‹æ ‡è®°
    "error_details": error_msg
}

# âœ… æ ¼å¼ä¸€è‡´æ€§è‰¯å¥½ - å¤±è´¥æ—¶è¿”å›ç©ºrisk_signalsè€ŒéNone
# âœ… åŒ…å«è¯¦ç»†é”™è¯¯åˆ†ç±» - ä¾¿äºåç»­è¯Šæ–­
```

**ç»“è®º**: 
- **PDFå·²ä¸‹è½½ä½†ç¼“å­˜**: æ£€æŸ¥ `downloads/pmc_pdfs/` ç›®å½•,å¾ˆå¯èƒ½åªæœ‰3ä¸ªæ–‡ä»¶
- **æ‰«æç‰ˆPDF**: 24ä¸ªå¤±è´¥æ–‡ä»¶ä¸­å¯èƒ½æœ‰å¤§é‡æ˜¯image-only PDF
- **ç¼ºå°‘OCR fallback**: è¿™æ˜¯æœ€å…³é”®çš„ç¼ºå¤±åŠŸèƒ½!

### 5.3 å¤±è´¥çº§è”æ•ˆåº”

```
PDFä¸‹è½½å¤±è´¥ (24/27)
    â†“
EvidenceEngineæå–å†…å®¹æå°‘ (3ä¸ªæœ‰æ•ˆæ–‡ä»¶)
    â†“
compiled_evidence_textåªæœ‰5K chars (æ­£å¸¸åº”è¯¥ >100K)
    â†“
LLM promptä¸­çš„è¯æ®ä¸è¶³
    â†“
LLMæ— æ³•æ¨æ–­ compound_name, MoA, probabilityç­‰å­—æ®µ
    â†“
LLMè¿”å› null æˆ–çœç•¥è¿™äº›å­—æ®µ
    â†“
template_varså¡«å……é»˜è®¤å€¼ "[Data not available]"
    â†“
æœ€ç»ˆæŠ¥å‘Šä¸­å‡ºç°å¤§é‡ "[Data not available]"
```

### 5.4 ä¸ºä»€ä¹ˆæœ‰äº›éƒ¨åˆ†æœ‰å†…å®¹ï¼Ÿ

| éƒ¨åˆ† | æœ‰å†…å®¹ï¼Ÿ | åŸå›  |
|-----|---------|------|
| Executive Summary | âœ… | åŸºäº **å…ƒæ•°æ®** (117 trials, 60 failed) + å°‘é‡æœ‰æ•ˆPDF |
| Red Flags | âœ… | åŸºäº **ç»Ÿè®¡ç‰¹å¾** (failure rate 51.3%) |
| Bull/Bear/Black Swan | âœ… | åŸºäº **3ä¸ªæœ‰æ•ˆPDF** ä¸­æå–çš„æ ¸å¿ƒä¿¡æ¯ (EDIT-101 trial) |
| Clinical Trialsåˆ—è¡¨ | âœ… | ç›´æ¥æ¥è‡ª BioHarvestEngine å…ƒæ•°æ® (æ— éœ€PDF) |
| Risk Scores | âœ… | çº¯è®¡ç®— (ä¸ä¾èµ–PDFå†…å®¹) |
| Compound Name | âŒ | éœ€è¦ **è¯¦ç»†PDFå†…å®¹** è¯†åˆ«å…·ä½“è¯ç‰©å |
| MoA Description | âŒ | éœ€è¦ **æ·±åº¦é˜…è¯»** æå–ä½œç”¨æœºåˆ¶ |
| Probability % | âŒ | éœ€è¦ **å……åˆ†è¯æ®** è¿›è¡Œæ¦‚ç‡ä¼°ç®— |
| Final Rationale | âŒ | éœ€è¦ **å®Œæ•´æ•°æ®** æ”¯æŒå†³ç­–æ¨ç† |

### 5.5 ä¸‰å¤§é—®é¢˜æ·±åº¦è§£ç­” ğŸ’¡

#### é—®é¢˜1: PDFæå–æ–¹å¼æ”¹è¿›æ–¹æ¡ˆ

**ä½ çš„å»ºè®®**: æœ‰æ–‡æœ¬å±‚å°±æ­£å¸¸æå–,åªæœ‰å›¾ç‰‡å±‚å°±è°ƒç”¨Gemini Vision API OCR

**å½“å‰å®ç°çŠ¶æ€**:
```python
# src/tools/pdf_processor.py, line 159-280
def extract_text_from_pdf(pdf_path: str) -> str:
    # âœ… å·²å®ç°: æ£€æµ‹æ‰«æç‰ˆPDF
    if pages_without_text == total_pages:
        raise ValueError("SCANNED_PDF: All pages are images")
    
    # âŒ æœªå®ç°: OCR fallback
    # é‡åˆ°æ‰«æç‰ˆæ—¶ç›´æ¥æŠ›å‡ºé”™è¯¯,æ²¡æœ‰è°ƒç”¨Gemini Vision
```

**ç¼ºå¤±çš„å…³é”®åŠŸèƒ½**:
```python
# å½“å‰ç¼ºå°‘è¿™æ®µé€»è¾‘:
except ValueError as e:
    if "SCANNED_PDF" in str(e):
        # âŒ åº”è¯¥åœ¨è¿™é‡Œè°ƒç”¨ Gemini Vision OCR
        # return _extract_with_gemini_ocr(pdf_path)
        raise  # ä½†å®é™…ä¸Šç›´æ¥æŠ›å‡ºäº†
```

**âœ… ä½ çš„æ–¹æ¡ˆå®Œå…¨æ­£ç¡®!** å·²åœ¨7.1èŠ‚æä¾›å®Œæ•´å®ç°ä»£ç 

**æ•°æ®æ ¼å¼ä¸€è‡´æ€§ä¿è¯**:
1. **è¾“å…¥æ ¼å¼**: Gemini Visionæ¥æ”¶ `image_bytes` (PNG/JPEG)
   ```python
   pix = page.get_pixmap(dpi=300)
   img_bytes = pix.tobytes("png")  # â† æ ‡å‡†æ ¼å¼
   ```

2. **è¾“å‡ºæ ¼å¼**: OCRè¿”å›çº¯æ–‡æœ¬,ä¸PyMuPDFæ ¼å¼å®Œå…¨ä¸€è‡´
   ```python
   # PyMuPDFè¾“å‡º: "--- Page 1 ---\nText content\n\n"
   # Gemini OCRè¾“å‡º: "--- Page 1 ---\nText content\n\n"
   # æ ¼å¼ç»Ÿä¸€ âœ…
   ```

3. **é”™è¯¯å¤„ç†**: ç»Ÿä¸€è¿”å›ç©ºé£é™©åˆ—è¡¨
   ```python
   return {
       "paper_summary": "Error: OCR failed",
       "risk_signals": [],  # â† ç©ºåˆ—è¡¨,ä¸æ˜¯None
       "filename": "...",
       "error_type": "OCR_FAILED"
   }
   ```

---

#### é—®é¢˜2: PDFä¸‹è½½ç¼“å­˜é—®é¢˜

**ä½ çš„è´¨ç–‘**: æ˜¯å¦æœ‰äº›æ–‡ä»¶å·²ç»ä¸‹è½½è¿‡äº†,æ‰€ä»¥æ²¡æœ‰é‡å¤ä¸‹è½½?

**ä»£ç éªŒè¯**:
```python
# src/tools/pdf_downloader.py, line 100-115
def download_pdf_from_url(url: str, output_dir: str = "downloads") -> str:
    # ç”Ÿæˆç¼“å­˜æ–‡ä»¶å
    url_hash = hashlib.md5(url.encode()).hexdigest()
    filename = f"{pmc_id}_{url_hash[:8]}.pdf"
    file_path = save_dir / filename
    
    # ç¼“å­˜æ£€æŸ¥
    if file_path.exists() and file_path.stat().st_size > 5000:  # >5KB
        logger.info(f"âš¡ PDF cached: {file_path}")
        return str(file_path.absolute())  # â† ç›´æ¥è¿”å›è·¯å¾„
    
    # å¦åˆ™å°è¯•ä¸‹è½½...
```

**å®é™…æƒ…å†µåˆ†æ**:

| åœºæ™¯ | æ–‡ä»¶çŠ¶æ€ | å‡½æ•°è¡Œä¸º | ç»“æœ |
|------|---------|---------|------|
| **æ–‡ä»¶å·²å­˜åœ¨ä¸”>5KB** | âœ… å®Œæ•´ | è·³è¿‡ä¸‹è½½,è¿”å›è·¯å¾„ | **è¿›å…¥æå–æµç¨‹** |
| **æ–‡ä»¶å·²å­˜åœ¨ä½†<5KB** | âŒ æŸå | é‡æ–°ä¸‹è½½ | å¯èƒ½å†æ¬¡å¤±è´¥ |
| **æ–‡ä»¶ä¸å­˜åœ¨** | âŒ æ—  | å°è¯•ä¸‹è½½ | å¦‚æœURLå¤±æ•ˆåˆ™å¤±è´¥ |
| **æ–‡ä»¶æ˜¯0å­—èŠ‚** | âŒ ç©º | ä¸æ»¡è¶³>5KB,é‡æ–°ä¸‹è½½ | å¾ªç¯å¤±è´¥ |

**å…³é”®å‘ç°**:
```bash
# æ£€æŸ¥å®é™…æ–‡ä»¶çŠ¶æ€ (åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ):
ls -lh downloads/pmc_pdfs/ | wc -l
# é¢„æµ‹ç»“æœ: çº¦3-5ä¸ªæ–‡ä»¶ (åªæœ‰æˆåŠŸä¸‹è½½çš„)

# æ£€æŸ¥æ˜¯å¦æœ‰æŸåæ–‡ä»¶:
find downloads/pmc_pdfs/ -type f -size -5k
# å¦‚æœæœ‰è¾“å‡º,è¯´æ˜å­˜åœ¨<5KBçš„æŸåæ–‡ä»¶
```

**ç»“è®º**: 
- âœ… **ç¼“å­˜é€»è¾‘æ­£ç¡®** - ä¸ä¼šé‡å¤ä¸‹è½½å·²æœ‰æ–‡ä»¶
- âŒ **é—®é¢˜åœ¨ä¸Šæ¸¸** - 24ä¸ªPDFæ ¹æœ¬æ²¡ä¸‹è½½æˆåŠŸ (URLå¤±æ•ˆ/403é™æµ)
- âš ï¸ **éšè—é—®é¢˜** - å¦‚æœæœ‰<5KBçš„æŸåæ–‡ä»¶ä¼šå¾ªç¯é‡è¯•

**å»ºè®®æ”¹è¿›**:
```python
# å¢å¼ºç¼“å­˜é€»è¾‘
if file_path.exists():
    file_size = file_path.stat().st_size
    if file_size > 5000:
        logger.info(f"âš¡ PDF cached: {file_path}")
        return str(file_path.absolute())
    else:
        logger.warning(f"âš ï¸ Cached file too small ({file_size} bytes), re-downloading...")
        file_path.unlink()  # åˆ é™¤æŸåæ–‡ä»¶
        # ç»§ç»­ä¸‹è½½...
```

---

#### é—®é¢˜3: Promptçº¦æŸæ˜¯å¦å¯¼è‡´"Data not available"

**ä½ çš„è´¨ç–‘**: æ˜¯å› ä¸ºè¿™æ®µpromptå¯¼è‡´çš„å—?

**ä»£ç å®šä½**:
```python
# src/agents/report_writer.py, line 450-470
synthesis_prompt = f"""
**CRITICAL WARNING:**
- 24/27 PDFs failed
- confidence_score: 2.1/10
- You MUST state "[Data not available]" for sections without evidence
- DO NOT invent data
- If uncertain, return null instead of guessing
"""
```

**A/Bå¯¹æ¯”å®éªŒ** (ç†è®ºåˆ†æ):

| Promptæ¨¡å¼ | æ•°æ®çŠ¶æ€ | LLMè¡Œä¸º | æŠ¥å‘Šè´¨é‡ |
|-----------|---------|---------|---------|
| **ä¸¥æ ¼æ¨¡å¼** (å½“å‰) | 3/27 æœ‰æ•ˆPDF | å¤§é‡è¿”å›null | âœ… ç§‘å­¦ä¸¥è°¨<br>âŒ ä¿¡æ¯ä¸å®Œæ•´ |
| **å®½æ¾æ¨¡å¼** (å‡è®¾) | 3/27 æœ‰æ•ˆPDF | åŸºäºé€šç”¨çŸ¥è¯†å¡«å…… | âŒ å¯èƒ½ç¼–é€ <br>âœ… çœ‹èµ·æ¥å®Œæ•´ |
| **ç†æƒ³çŠ¶æ€** | 20/27 æœ‰æ•ˆPDF | åŸºäºå……åˆ†è¯æ®ç”Ÿæˆ | âœ… ç§‘å­¦ä¸¥è°¨<br>âœ… ä¿¡æ¯å®Œæ•´ |

**å› æœé“¾åˆ†æ**:

```
æ ¹æœ¬åŸå› : PDFæå–å¤±è´¥ (24/27)
    â†“
ç›´æ¥åæœ: compiled_evidence_textåªæœ‰5K chars
    â†“
LLMæ„ŸçŸ¥: "è¯æ®ä¸¥é‡ä¸è¶³"
    â†“
åˆ†æ”¯A (ä¸¥æ ¼prompt): è¿”å›null â†’ "[Data not available]"
åˆ†æ”¯B (å®½æ¾prompt): ç¼–é€ å†…å®¹ â†’ "CRISPR-Cas9 typically..." (æ— å‡ºå¤„)
```

**å®éªŒéªŒè¯æ–¹æ¡ˆ**:

```python
# å¯¹æ¯”æµ‹è¯•: ä¿®æ”¹promptçœ‹æ•ˆæœ

# Version A: ä¸¥æ ¼æ¨¡å¼ (å½“å‰)
prompt_strict = """
- You MUST state "[Data not available]" for sections without evidence
- DO NOT invent data
"""

# Version B: å®½æ¾æ¨¡å¼ (æµ‹è¯•)
prompt_relaxed = """
- If evidence is insufficient, you MAY use general biomedical knowledge
- Clearly mark speculative sections with "Note: Based on general knowledge"
"""

# Version C: å¹³è¡¡æ¨¡å¼ (æ¨è)
prompt_balanced = """
- If evidence is insufficient for detailed analysis, provide:
  1. What CAN be determined from available data
  2. What CANNOT be determined (mark as "Insufficient data")
  3. General context (clearly labeled as "Background information")
"""
```

**ç»“è®º**:

1. **Promptçº¦æŸæ˜¯"æ”¾å¤§å™¨"è€Œé"æ ¹æº"**
   - å¦‚æœæœ‰20ä¸ªæœ‰æ•ˆPDF,å³ä½¿ä¸¥æ ¼promptä¹Ÿèƒ½ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
   - å¦‚æœåªæœ‰3ä¸ªæœ‰æ•ˆPDF,å³ä½¿å®½æ¾promptä¹Ÿä¼šç¼–é€ å†…å®¹

2. **æƒè¡¡å–èˆ**:
   ```
   ä¸¥æ ¼prompt: è¯šå®ä½†ä¸å®Œæ•´
   å®½æ¾prompt: å®Œæ•´ä½†ä¸å¯ä¿¡
   å¹³è¡¡prompt: åˆ†å±‚æŠ«éœ² (æ¨è)
   ```

3. **å»ºè®®æ”¹è¿›** (è§7.2èŠ‚ "æ¸è¿›å¼æŠ¥å‘Šç”Ÿæˆ"):
   ```python
   if confidence >= 7.0:
       use_strict_prompt()  # å®Œæ•´æŠ¥å‘Š
   elif confidence >= 3.0:
       use_balanced_prompt()  # éƒ¨åˆ†æŠ¥å‘Š+èƒŒæ™¯çŸ¥è¯†
   else:
       use_minimal_prompt()  # åªç”Ÿæˆå…ƒæ•°æ®åˆ†æ
   ```

**å®é™…ä¿®å¤ä¼˜å…ˆçº§**:
1. ğŸ”¥ **æœ€é«˜ä¼˜å…ˆ**: å®ç°Gemini OCR fallback (æå‡æ•°æ®å®Œæ•´æ€§)
2. âš™ï¸ **ä¸­ç­‰ä¼˜å…ˆ**: æ”¹è¿›PDFä¸‹è½½é‡è¯•é€»è¾‘
3. ğŸ¨ **ä½ä¼˜å…ˆ**: è°ƒæ•´promptç­–ç•¥ (åœ¨æ•°æ®å……è¶³åå†ä¼˜åŒ–)

---

### 5.6 ç»¼åˆè¯Šæ–­ç»“è®º

**æ ¸å¿ƒé—®é¢˜çŸ©é˜µ**:

| é—®é¢˜ç±»å‹ | å½“å‰çŠ¶æ€ | å½±å“ç¨‹åº¦ | ä¿®å¤éš¾åº¦ | ä¼˜å…ˆçº§ |
|---------|---------|---------|---------|--------|
| **PDFæå–å¤±è´¥** | âŒ æ— OCR fallback | ğŸ”´ ä¸¥é‡ (å¯¼è‡´89%å¤±è´¥ç‡) | ğŸŸ¡ ä¸­ç­‰ (éœ€é›†æˆGemini Vision) | P0 |
| **PDFä¸‹è½½é™æµ** | âš ï¸ æœ‰é‡è¯•,ä½†ä¸å¤Ÿrobust | ğŸŸ  é«˜ (åˆå§‹æ•°æ®è·å–é˜¶æ®µ) | ğŸŸ¢ ç®€å• (å¢åŠ æŒ‡æ•°é€€é¿) | P1 |
| **Promptè¿‡äºä¸¥æ ¼** | âš ï¸ è®¾è®¡trade-off | ğŸŸ¡ ä¸­ç­‰ (æ”¾å¤§æ•°æ®ä¸è¶³é—®é¢˜) | ğŸŸ¢ ç®€å• (è°ƒæ•´wording) | P2 |
| **ç¼“å­˜æŸåæ–‡ä»¶** | âš ï¸ ç†è®ºé—®é¢˜ | ğŸŸ¢ ä½ (ç½•è§åœºæ™¯) | ğŸŸ¢ ç®€å• (å¢åŠ æ¸…ç†é€»è¾‘) | P3 |

**ä¿®å¤åé¢„æœŸæ•ˆæœ**:

```
å½“å‰çŠ¶æ€:
â”œâ”€ 27 PDFs attempted
â”œâ”€ 3 successfully extracted (11%)
â”œâ”€ 24 failed (89%)
â”‚   â”œâ”€ 15 SCANNED_PDF (~62%)
â”‚   â”œâ”€ 6 DOWNLOAD_FAILED (~25%)
â”‚   â””â”€ 3 CORRUPTED_PDF (~13%)
â””â”€ confidence_score: 2.1/10

ä¿®å¤åçŠ¶æ€ (é¢„æµ‹):
â”œâ”€ 27 PDFs attempted
â”œâ”€ 18 successfully extracted (67%)  â† +500% improvement
â”‚   â”œâ”€ 3 text-layer PDFs
â”‚   â”œâ”€ 10 OCR-rescued PDFs
â”‚   â””â”€ 5 retry-rescued PDFs
â”œâ”€ 9 failed (33%)
â”‚   â”œâ”€ 3 corrupted beyond repair
â”‚   â”œâ”€ 3 heavily encrypted
â”‚   â””â”€ 3 network timeouts
â””â”€ confidence_score: 6.7/10  â† +219% improvement

æŠ¥å‘Šå®Œæ•´åº¦:
â”œâ”€ "[Data not available]" count: 13 â†’ 3  â† -77%
â”œâ”€ compound_name: null â†’ "EDIT-101"
â”œâ”€ moa_description: null â†’ "CRISPR-Cas9 nuclease..."
â”œâ”€ probability_bull: null â†’ "35%"
â””â”€ final_recommendation: null â†’ "PROCEED WITH CAUTION"
```

**å…³é”®æ´å¯Ÿ**: 
- PDFæå–æ˜¯æ•´ä¸ªpipelineçš„"å’½å–‰è¦é“",ä¿®å¤å®ƒèƒ½è§£å†³80%çš„é—®é¢˜
- Promptçº¦æŸä¸æ˜¯æ•Œäºº,è€Œæ˜¯è´¨é‡æ§åˆ¶æœºåˆ¶
- æ•°æ®å®Œæ•´æ€§æå‡å,å³ä½¿ä¿æŒä¸¥æ ¼promptä¹Ÿèƒ½ç”Ÿæˆå®Œæ•´æŠ¥å‘Š

---

## 6. å…³é”®ä»£ç è·¯å¾„

### 6.1 PDFå¤±è´¥å¤„ç†è·¯å¾„

```python
# 1. PDFä¸‹è½½ (BioHarvestEngine/agent.py, line 350-400)
def _download_pdfs(results):
    for paper in results:
        if 'pdf_url' in paper:
            try:
                local_path = download_pdf_from_url(paper['pdf_url'])
                paper['local_path'] = local_path
            except Exception as e:
                logger.error(f"Download failed: {e}")
                paper['local_path'] = None  # â† æ ‡è®°å¤±è´¥

# 2. PDFæå– (supervisor.py, miner_node, line 180-250)
def miner_node(state):
    failed_files = []
    for pdf_path in state['pdf_paths']:
        if not pdf_path or not os.path.exists(pdf_path):
            failed_files.append(pdf_path)  # â† è¿½è¸ªå¤±è´¥
            continue
        try:
            text = extract_text(pdf_path)
            # ... å¤„ç†
        except Exception as e:
            failed_files.append(pdf_path)  # â† æ•è·é”™è¯¯
    
    return {
        'text_evidence': [...],
        'failed_files': failed_files,  # â† ä¼ é€’å¤±è´¥ä¿¡æ¯
        'total_files': len(state['pdf_paths'])
    }

# 3. å¤±è´¥ä¿¡æ¯ä¼ æ’­ (supervisor.py, graph_builder_node, line 400-450)
def graph_builder_node(state):
    failed_count = len(state.get('failed_files', []))
    total_files = state.get('total_files', 0)
    
    # è®¡ç®—ç½®ä¿¡åº¦
    valid_files = total_files - failed_count
    confidence_score = (valid_files / total_files * 10) if total_files > 0 else 0
    
    # å†³å®šé£é™©è¦†ç›–
    if failed_count == total_files:
        risk_override = "UNCERTAIN (ALL DATA EXTRACTION FAILED)"
    elif failed_count > total_files * 0.5:
        risk_override = "UNCERTAIN (MAJORITY OF DATA EXTRACTION FAILED)"
    
    return {
        'confidence_score': confidence_score,  # â† 2.1
        'risk_override': risk_override,  # â† "UNCERTAIN"
        'failed_count': failed_count  # â† 24
    }

# 4. æŠ¥å‘Šç”Ÿæˆæ—¶çš„å¤±è´¥æŠ«éœ² (report_writer.py, line 420-480)
def _synthesize_evidence(..., failed_count, confidence_score):
    failure_disclosure = f"""
    âš ï¸ **CRITICAL DATA INTEGRITY NOTICE:**
    - Files Failed: {failed_count} ({failure_rate}%)
    - Confidence Score: {confidence_score}/10
    
    YOU MUST:
    - Acknowledge this failure in Executive Summary
    - Use "[Data not available]" for unsupported sections
    - DO NOT invent data
    """
    
    prompt = f"{failure_disclosure}\n\n{evidence_summary}"
    synthesized = llm.generate(prompt)
    return synthesized
```

### 6.2 Data not availableå¡«å……è·¯å¾„

```python
# report_writer.py, line 880-960

def _render_markdown(report_data, synthesized_sections, risk_analysis):
    # 1. å‡†å¤‡æ¨¡æ¿å˜é‡ (å¡«å……é»˜è®¤å€¼)
    template_vars = {
        # æœ‰æ•°æ®çš„å­—æ®µ
        'executive_summary_text': synthesized_sections.get('executive_summary', ''),
        'bull_case': synthesized_sections.get('bull_case', ''),
        
        # å¯èƒ½ç¼ºå¤±çš„å­—æ®µ (ä½¿ç”¨ or è¿ç®—ç¬¦)
        'compound_name': synthesized_sections.get('compound_name') or '[Data not available]',
        'moa_description': synthesized_sections.get('moa_description') or '[Data not available]',
        'probability_bull': synthesized_sections.get('probability_bull') or '[Data not available]',
        # ... å…¶ä»–å­—æ®µ
    }
    
    # 2. æ¨¡æ¿æ¸²æŸ“
    rendered = self.template
    for key, value in template_vars.items():
        rendered = ğŸ”¥ **ã€æœ€é«˜ä¼˜å…ˆçº§ã€‘**

**æ–¹æ¡ˆ: å¤šç­–ç•¥PDFæå– + Gemini Vision OCR Fallback**

```python
# src/tools/pdf_processor.py

def extract_text_from_pdf(pdf_path: str) -> str:
    """
    å¤šç­–ç•¥PDFæå–ç®¡é“:
    1. PyMuPDF (æ–‡æœ¬å±‚)
    2. PDFMiner (å¤‡é€‰æ–‡æœ¬å±‚)
    3. Gemini Vision OCR (å›¾åƒå±‚)
    """
    
    # === STAGE 1: å°è¯•æ–‡æœ¬å±‚æå– ===
    try:
        # ç­–ç•¥1: PyMuPDF (æœ€å¿«,æ”¯æŒ95%çš„PDF)
        text = _extract_with_pymupdf(pdf_path)
        if len(text) > 500:
            logger.success(f"âœ… PyMuPDF extracted {len(text)} chars")
            return text
    except ValueError as e:
        if "SCANNED_PDF" in str(e):
            logger.warning("âš ï¸ PyMuPDF detected scanned PDF, trying OCR...")
        elif "ENCRYPTED_PDF" in str(e):
            raise  # æ— æ³•å¤„ç†åŠ å¯†PDF
        else:
            logger.warning(f"PyMuPDF failed: {e}, trying PDFMiner...")
    
    # === STAGE 2: PDFMinerå¤‡é€‰ ===
    try:
        # ç­–ç•¥2: PDFMiner (æ›´ç²¾ç¡®,å¤„ç†å¤æ‚å¸ƒå±€)
        text = _extract_with_pdfminer(pdf_path)
        if len(text) > 500:
            logger.success(f"âœ… PDFMiner extracted {len(text)} chars")
            return text
    except Exception as e:
        logger.warning(f"PDFMiner failed: {e}, trying OCR...")
    
    # === STAGE 3: Gemini Vision OCR (æœ€åæ‰‹æ®µ) ===
    logger.info("ğŸ” Falling back to Gemini Vision OCR...")
    try:
        text = _extract_with_gemini_ocr(pdf_path)
        if len(text) > 500:
            logger.success(f"âœ… Gemini OCR extracted {len(text)} chars")
            return text
    except Exception as e:
        logger.error(f"âŒ Gemini OCR failed: {e}")
        raise ValueError(f"ALL_METHODS_FAILED: {e}")


def _extract_with_gemini_ocr(pdf_path: str) -> str:
    """
    ä½¿ç”¨Gemini Vision APIå¯¹PDFæ¯ä¸€é¡µè¿›è¡ŒOCR
    
    å…³é”®: ä¿æŒæ•°æ®æ ¼å¼ä¸€è‡´æ€§
    """
    import fitz
    from src.llms import create_forensic_client  # Gemini Vision client
    
    pdf = fitz.open(pdf_path)
    llm = create_forensic_client()
    
    all_text = []
    
    for page_num in range(len(pdf)):
        page = pdf[page_num]
        
        # å°†PDFé¡µé¢è½¬ä¸ºå›¾åƒ (PNG bytes)
        pix = page.get_pixmap(dpi=300)
        img_bytes = pix.tobytes("png")
        
        # Gemini Vision OCR
        prompt = """
        Extract ALL text from this scanned document page.
        Output ONLY the raw text, no explanations or formatting notes.
        Maintain original line breaks and paragraph structure.
        """
        
        try:
            # è°ƒç”¨Gemini Vision API (multimodal)
            response = llm.generate_content(
                prompt=prompt,
                image_bytes=img_bytes
            )
            
            page_text = response.text.strip()
            if page_text:
                all_text.append(f"--- Page {page_num + 1} ---")
                all_text.append(page_text)
                all_text.append("")  # ç©ºè¡Œåˆ†éš”
                
        except Exception as e:
            logger.warning(f"âš ï¸ OCR failed for page {page_num + 1}: {e}")
            continue
    
    pdf.close()
    
    final_text = "\n".join(all_text)
    logger.info(f"ğŸ“Š OCR extracted {len(final_text)} chars from {len(pdf)} pages")
    
    return final_text


def _extract_with_pdfminer(pdf_path: str) -> str:
    """PDFMinerå¤‡é€‰æ–¹æ¡ˆ"""
    from pdfminer.high_level import extract_text as pdfminer_extract
    
    text = pdfminer_extract(pdf_path)
    return text
```

**å®æ–½æ­¥éª¤**:
1. ä¿®æ”¹ `src/tools/pdf_processor.py` æ·»åŠ ä¸Šè¿°ä»£ç 
2. å®‰è£…ä¾èµ–: `pip install pdfminer.six`
3. ç¡®ä¿Gemini Vision APIé…ç½®æ­£ç¡® (å·²åœ¨ `src/llms/` ä¸­)
4. æµ‹è¯•: ç”¨ä¸€ä¸ªæ‰«æç‰ˆPDFéªŒè¯OCRåŠŸèƒ½

**é¢„æœŸæ•ˆæœ**:
- 24ä¸ªå¤±è´¥PDFä¸­,å‡è®¾15ä¸ªæ˜¯æ‰«æç‰ˆ,OCRå¯æ•‘å›çº¦70% (10ä¸ª)
- æ•°æ®å®Œæ•´æ€§ä»11% â†’ çº¦48% (13/27)
- confidence_scoreä»2.1 â†’ çº¦5.0
- "[Data not available]"æ•°é‡å‡å°‘çº¦60%         validated.append({
                'image_id': item.get('image_id', 'unknown'),
                'status': item.get('status', 'ERROR'),
                'tampering_risk_score': item.get('tampering_risk_score'),
                'findings': item.get('findings', 'No analysis available')
            })
        return validated
    
    @staticmethod
    def validate_evidence_payload(data: List[Dict]) -> List[Dict]:
        """éªŒè¯EvidenceEngineè¾“å‡º"""
        validated = []
        for item in data:
            validated.append({
                'source': item.get('source', 'Unknown'),
                'risk_level': item.get('risk_level', 'UNKNOWN'),
                'quote': item.get('quote', ''),
                'explanation': item.get('explanation', 'No explanation')
            })
        return validated
```

---

## 7. æ”¹è¿›å»ºè®®

### 7.1 çŸ­æœŸä¿®å¤ (Quick Wins)

#### 1. å¢å¼ºPDFæå–é²æ£’æ€§
```python
# BioHarvestEngine/agent.py

def extract_text_from_pdf(pdf_path: str) -> str:
    """å¤šç­–ç•¥PDFæå–"""
    try:
        # ç­–ç•¥1: PyMuPDF (æœ€å¿«)
        text = pymupdf_extract(pdf_path)
        if len(text) > 500:
            return text
    except:
        pass
    
    try:
        # ç­–ç•¥2: PDFMiner (æ›´ç²¾ç¡®)
        text = pdfminer_extract(pdf_path)
        if len(text) > 500:
            return text
    except:
        pass
    
    try:
        # ç­–ç•¥3: OCR (æ‰«æç‰ˆPDF)
        text = tesseract_ocr(pdf_path)
        if len(text) > 500:
            return text
    except:
        pass
    
    raise ValueError("All extraction methods failed")
```

#### 2. PDFä¸‹è½½é‡è¯•æœºåˆ¶
```python
# src/tools/pdf_downloader.py

def download_pdf_with_retry(url: str, max_retries=3) -> Optional[str]:
    for attempt in range(max_retries):
        try:
            response = requests.get(url, timeout=30)
            if response.status_code == 200:
                return save_pdf(response.content)
        except Exception as e:
            logger.warning(f"Download attempt {attempt+1} failed: {e}")
            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
    
    return None  # æ‰€æœ‰é‡è¯•å¤±è´¥
```

#### 3. æ”¹è¿›å¤±è´¥æŠ«éœ²æ ¼å¼
```python
# report_writer.py

def _synthesize_evidence(...):
    if failed_count > 0:
        failure_disclosure = f"""
        ## âš ï¸ DATA QUALITY ALERT
        
        **Analysis Status:** {'CRITICAL' if failed_count == total_files else 'PARTIAL'}
        **Files Processed Successfully:** {total_files - failed_count}/{total_files}
        **Confidence Score:** {confidence_score:.1f}/10
        
        **Failed Files:**
        {chr(10).join(f'- {f}' for f in failed_files[:10])}
        {'... and ' + str(len(failed_files) - 10) + ' more' if len(failed_files) > 10 else ''}
        
        **Impact:**
        - Risk assessment may be INACCURATE due to missing data
        - Treat "[Data not available]" sections with extreme caution
        - Consider re-running analysis with alternative data sources
        """
```

### 7.2 ä¸­æœŸä¼˜åŒ–

#### 1. æ™ºèƒ½PDFæ¥æºåˆ‡æ¢
```python
# BioHarvestEngine/agent.py

class SmartPDFHarvester:
    def harvest_pdfs(self, query: str):
        # ä¼˜å…ˆçº§é˜Ÿåˆ—
        sources = [
            ('EuroPMC', self.europmc_client, priority=1),  # ç›´æ¥PDFä¸‹è½½
            ('ArXiv', self.arxiv_client, priority=2),  # é¢„å°æœ¬
            ('BioRxiv', self.biorxiv_client, priority=3),
            ('PubMed', self.pubmed_scraper, priority=4),  # éœ€è¦çˆ¬è™«
            ('Sci-Hub', self.scihub_client, priority=5)  # æœ€åæ‰‹æ®µ
        ]
        
        for source_name, client, _ in sorted(sources, key=lambda x: x[2]):
            try:
                pdfs = client.search_and_download(query)
                if len(pdfs) >= MIN_REQUIRED_PDFS:
                    return pdfs
            except Exception as e:
                logger.warning(f"{source_name} failed: {e}")
                continue
        
        return []  # æ‰€æœ‰æ¥æºå¤±è´¥
```

#### 2. æ¸è¿›å¼æŠ¥å‘Šç”Ÿæˆ
```python
# report_writer.py

def generate_progressive_report(data, min_confidence=3.0):
    """æ ¹æ®æ•°æ®è´¨é‡ç”Ÿæˆä¸åŒæ·±åº¦çš„æŠ¥å‘Š"""
    
    confidence = calculate_confidence(data)
    
    if confidence >= 7.0:
        # å®Œæ•´æŠ¥å‘Š (æ‰€æœ‰sections)
        return generate_full_report(data)
    
    elif confidence >= min_confidence:
        # éƒ¨åˆ†æŠ¥å‘Š (åªåŒ…å«é«˜ç½®ä¿¡åº¦sections)
        return generate_partial_report(data, exclude=[
            'compound_name', 'moa_description',  # éœ€è¦è¯¦ç»†æ•°æ®
            'probability_weights', 'expected_outcome'
        ])
    
    else:
        # æœ€å°æŠ¥å‘Š (åªæœ‰å…ƒæ•°æ®åˆ†æ)
        return generate_minimal_report(data, include=[
            'executive_summary', 'trial_statistics',
            'data_quality_warning'
        ])
```

#### 3. LLM Self-Reflection
```python
# report_writer.py

def _synthesize_with_reflection(evidence_summary):
    """è®©LLMè‡ªæˆ‘æ£€æŸ¥å¹¶æ ‡æ³¨ä¸ç¡®å®šæ€§"""
    
    synthesis_prompt = f"""
    {evidence_summary}
    
    Generate report sections with CONFIDENCE TAGS:
    
    {{
      "executive_summary": {{
        "text": "...",
        "confidence": 0.8,  // 0.0-1.0
        "data_sources": ["Trial NCT123", "Paper PMC456"]
      }},
      "compound_name": {{
        "text": "EDIT-101",
        "confidence": 0.3,  // Low confidence!
        "reason": "Only mentioned once in limited context"
      }}
    }}
    
    Rules:
    - confidence < 0.5 â†’ Return null instead
    - confidence 0.5-0.7 â†’ Include uncertainty disclaimer
    - confidence > 0.7 â†’ Normal output
    """
    
    result = llm.generate(synthesis_prompt)
    
    # åå¤„ç†: è¿‡æ»¤ä½ç½®ä¿¡åº¦å­—æ®µ
    for key, value in result.items():
        if value['confidence'] < 0.5:
            result[key] = None  # ä¸å¦‚ä¸å†™
    
    return result
```

### 7.3 é•¿æœŸé‡æ„

#### 1. å¼•å…¥æ•°æ®æ¹– (Data Lake)
```
downloads/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ pdfs/
â”‚   â”œâ”€â”€ html/
â”‚   â””â”€â”€ json/
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ extracted_text/
â”‚   â”œâ”€â”€ structured_data/
â”‚   â””â”€â”€ embeddings/
â””â”€â”€ cache/
    â””â”€â”€ llm_responses/
```

#### 2. å¢é‡åˆ†æpipeline
```python
class IncrementalAnalysisPipeline:
    def run(self, query):
        # Stage 1: å¿«é€Ÿå…ƒæ•°æ®æ”¶é›† (30ç§’)
        stage1 = self.harvest_metadata(query)
        emit_progress(stage='metadata', data=stage1)
        
        # Stage 2: PDFä¸‹è½½ (2-5åˆ†é’Ÿ)
        stage2 = self.download_pdfs(stage1)
        emit_progress(stage='download', success_rate=stage2.success_rate)
        
        # Stage 3: æ–‡æœ¬æå– (5-10åˆ†é’Ÿ)
        stage3 = self.extract_texts(stage2.pdfs)
        emit_progress(stage='extraction', valid_files=stage3.valid_count)
        
        # Stage 4: è¯æ®æŒ–æ˜ (10-20åˆ†é’Ÿ)
        stage4 = self.mine_evidence(stage3.texts)
        
        # Stage 5: æŠ¥å‘Šç”Ÿæˆ (å®æ—¶)
        report = self.generate_report_incremental(stage1, stage2, stage3, stage4)
        # â†’ ç”¨æˆ·å¯ä»¥çœ‹åˆ°æŠ¥å‘Šé€æ­¥å®Œå–„
```

#### 3. å¤šæ¨¡å‹èåˆ
```python
class EnsembleReportWriter:
    def __init__(self):
        self.models = [
            ('gemini-pro', 0.5),  # é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›å¼º
            ('gpt-4', 0.3),  # æ¨ç†èƒ½åŠ›å¼º
            ('claude-3', 0.2)  # ç§‘å­¦å†™ä½œå¼º
        ]
    
    def generate_section(self, section_name, evidence):
        outputs = []
        for model_name, weight in self.models:
            output = self.llm_clients[model_name].generate(
                prompt=f"Generate {section_name} section",
                context=evidence
            )
            outputs.append((output, weight))
        
        # åŠ æƒèåˆ
        final_output = self.weighted_merge(outputs)
        return final_output
```

---

## é™„å½•

### A. æœ¯è¯­è¡¨

| æœ¯è¯­ | å®šä¹‰ |
|------|------|
| **Dark Data** | åŸ‹è—åœ¨è¡¥å……ææ–™ã€è„šæ³¨ä¸­çš„è´Ÿé¢ç»“æœ |
| **Red Flag** | ç§‘å­¦ç ”ç©¶ä¸­çš„å¯ç–‘ä¿¡å· (å¦‚på€¼>0.05, å—è¯•è€…é€€å‡º) |
| **Forensic Audit** | å›¾åƒå–è¯åˆ†æ (æ£€æµ‹Western Blotæ‹¼æ¥ç­‰) |
| **LangGraph** | å¤šæ™ºèƒ½ä½“ç¼–æ’æ¡†æ¶ (ç±»ä¼¼DAGå·¥ä½œæµ) |
| **StreamValidator** | æ•°æ®éªŒè¯ä¸­é—´ä»¶ (é˜²æ­¢LLMè¾“å‡ºå¯¼è‡´å´©æºƒ) |
| **Risk Override** | å½“æ•°æ®è´¨é‡å·®æ—¶å¼ºåˆ¶è®¾ç½®çš„é£é™©ç­‰çº§ |
| **Confidence Score** | æ•°æ®å®Œæ•´æ€§è¯„åˆ† (0-10) |

### B. æ–‡ä»¶ç»“æ„é€ŸæŸ¥

```
Cassandra/
â”œâ”€â”€ app.py                      # Flask APIå…¥å£
â”œâ”€â”€ main.py                     # CLIå…¥å£
â”œâ”€â”€ config.py                   # é…ç½®ç®¡ç†
â”œâ”€â”€ BioHarvestEngine/           # æ–‡çŒ®/è¯•éªŒæ”¶é›†
â”‚   â””â”€â”€ agent.py
â”œâ”€â”€ EvidenceEngine/             # æš—æ•°æ®æŒ–æ˜
â”‚   â””â”€â”€ agent.py
â”œâ”€â”€ ForensicEngine/             # å›¾åƒå–è¯
â”‚   â””â”€â”€ agent.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ supervisor.py       # LangGraphç¼–æ’
â”‚   â”‚   â””â”€â”€ report_writer.py    # æŠ¥å‘Šç”Ÿæˆ
â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â””â”€â”€ state.py            # AgentStateå®šä¹‰
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ biomedical_report.md  # æŠ¥å‘Šæ¨¡æ¿
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ stream_validator.py  # æ•°æ®éªŒè¯
â”‚   â””â”€â”€ llms/                   # LLMå®¢æˆ·ç«¯
â”œâ”€â”€ downloads/
â”‚   â””â”€â”€ pmc_pdfs/               # ä¸‹è½½çš„PDF
â””â”€â”€ final_reports/              # æœ€ç»ˆæŠ¥å‘Šè¾“å‡º
```

### C. è°ƒè¯•æ£€æŸ¥æ¸…å•

å½“æŠ¥å‘Šå‡ºç°å¤§é‡ "[Data not available]" æ—¶:

1. âœ… æ£€æŸ¥ `failed_files` æ•°é‡
   ```python
   # åœ¨reportä¸­æœç´¢ "Files Processed:"
   # å¦‚æœ failed > 50%, éœ€è¦æ”¹è¿›PDFæå–
   ```

2. âœ… æ£€æŸ¥ `confidence_score`
   ```python
   # åœ¨reportä¸­æœç´¢ "Confidence Score:"
   # å¦‚æœ < 3.0, æ•°æ®è´¨é‡ä¸è¶³ä»¥ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
   ```

3. âœ… æ£€æŸ¥ `compiled_evidence_text` å¤§å°
   ```python
   # æŸ¥çœ‹logs: "Final Context Payload: X chars"
   # å¦‚æœ < 10,000 chars, LLMè¾“å…¥ä¸è¶³
   ```

4. âœ… æ£€æŸ¥LLMè¾“å‡ºçš„JSONå®Œæ•´æ€§
   ```python
   # æŸ¥çœ‹logs: "Synthesized X report sections"
   # å¦‚æœ < 15 sections, è¯´æ˜LLMè·³è¿‡äº†éƒ¨åˆ†å­—æ®µ
   ```

5. âœ… æ£€æŸ¥PDFä¸‹è½½æ—¥å¿—
   ```python
   # æŸ¥çœ‹logs: "Download failed: ..."
   # å¸¸è§åŸå› : 403 Forbidden, 404 Not Found, Timeout
   ```

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2026-02-09  
**åˆ†æäººå‘˜**: Cassandraå·¥ç¨‹å›¢é˜Ÿ  
**ç‰ˆæœ¬**: v1.0
