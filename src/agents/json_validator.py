"""
JSONéªŒè¯å™¨å’Œä¿®å¤å™¨ - ç¡®ä¿Geminiç”Ÿæˆçš„JSONæ ¼å¼æ­£ç¡®

è¿™ä¸ªæ¨¡å—æä¾›:
1. JSONæ ¼å¼éªŒè¯å’Œè‡ªåŠ¨ä¿®å¤
2. æ£€æŸ¥å®˜è§’è‰² - éªŒè¯JSONå®Œæ•´æ€§
3. åˆ†æ®µJSONç”Ÿæˆç®¡ç†å™¨
"""

import json
import re
from typing import Dict, Any, List, Optional, Tuple
from loguru import logger


class JSONValidator:
    """JSONæ ¼å¼éªŒè¯å™¨å’Œä¿®å¤å™¨"""
    
    @staticmethod
    def validate_and_repair(json_text: str, expected_fields: List[str]) -> Tuple[bool, Optional[Dict], List[str]]:
        """
        éªŒè¯JSONå¹¶å°è¯•ä¿®å¤å¸¸è§é”™è¯¯
        
        Args:
            json_text: å¾…éªŒè¯çš„JSONæ–‡æœ¬
            expected_fields: æœŸæœ›çš„å­—æ®µåˆ—è¡¨
        
        Returns:
            (is_valid, parsed_data, errors)
        """
        errors = []
        
        # ğŸ”¥ CRITICAL FIX: Check for None or empty input
        if json_text is None:
            logger.error("âŒ JSONValidator received None input")
            return False, None, ["Input is None"]
        
        if not json_text or not json_text.strip():
            logger.error("âŒ JSONValidator received empty input")
            return False, None, ["Input is empty"]
        
        # ğŸ”¥ STAGE 0: Try json-repair library first (most powerful)
        try:
            from json_repair import repair_json
            logger.info("ğŸ”§ Attempting json-repair library (Stage 0)...")
            
            repaired_obj = repair_json(json_text, return_objects=True)
            if isinstance(repaired_obj, dict):
                logger.success("âœ… json-repair library fixed JSON successfully")
                
                # Validate fields
                missing_fields = [f for f in expected_fields if f not in repaired_obj]
                if missing_fields:
                    errors.append(f"Missing fields: {', '.join(missing_fields)}")
                    for field in missing_fields:
                        repaired_obj[field] = "[Data not available]"
                
                return True, repaired_obj, errors
                
        except ImportError:
            logger.debug("json-repair library not available, using manual repair")
        except Exception as e:
            logger.debug(f"json-repair failed: {e}, falling back to manual repair")
        
        # 1. é¢„å¤„ç† - æ¸…ç†å¸¸è§é—®é¢˜
        cleaned = JSONValidator._preprocess_json(json_text)
        
        # 2. å°è¯•ç›´æ¥è§£æ
        try:
            data = json.loads(cleaned)
            
            # 3. éªŒè¯å¿…éœ€å­—æ®µ
            missing_fields = [f for f in expected_fields if f not in data]
            if missing_fields:
                errors.append(f"Missing fields: {', '.join(missing_fields)}")
                # è¡¥å……ç¼ºå¤±å­—æ®µ
                for field in missing_fields:
                    data[field] = "[Data not available]"
                logger.warning(f"ğŸ”§ Auto-filled {len(missing_fields)} missing fields")
            
            # 4. éªŒè¯å­—æ®µå€¼ä¸ä¸ºç©º
            empty_fields = [k for k, v in data.items() if not v or (isinstance(v, str) and v.strip() == "")]
            if empty_fields:
                errors.append(f"Empty fields: {', '.join(empty_fields)}")
                for field in empty_fields:
                    data[field] = "[Insufficient data]"
            
            logger.success(f"âœ… JSON validation passed with {len(errors)} warnings")
            return True, data, errors
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON parsing failed: {e}")
            # ğŸ”¥ NEW: æ˜¾ç¤ºé”™è¯¯ä¸Šä¸‹æ–‡ä»¥ä¾¿è°ƒè¯•
            if hasattr(e, 'pos') and e.pos < len(cleaned):
                error_start = max(0, e.pos - 50)
                error_end = min(len(cleaned), e.pos + 50)
                context = cleaned[error_start:error_end]
                logger.error(f"Error context at position {e.pos}:")
                logger.error(f"...{context}...")
            else:
                logger.error(f"First 200 chars of problematic JSON:")
                logger.error(f"{cleaned[:200]}")
            
            errors.append(f"JSON decode error: {e}")
            
            # 5. å°è¯•é«˜çº§ä¿®å¤ç­–ç•¥
            repaired_data = JSONValidator._advanced_repair(cleaned, expected_fields, e)
            if repaired_data:
                logger.success("âœ… JSON repaired successfully via advanced strategies")
                return True, repaired_data, errors
            
            return False, None, errors
    
    @staticmethod
    def _preprocess_json(text: str) -> str:
        """é¢„å¤„ç†JSONæ–‡æœ¬ï¼Œä¿®å¤å¸¸è§æ ¼å¼é—®é¢˜"""
        # ğŸ”¥ DEBUG: è®°å½•åŸå§‹å“åº”çš„å‰200å­—ç¬¦
        logger.debug(f"ğŸ“¥ Raw JSON input (first 200 chars): {text[:200]}")
        
        # ç§»é™¤markdownä»£ç å—æ ‡è®°
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0].strip()
            logger.debug("ğŸ”§ Removed markdown ```json wrapper")
        elif "```" in text:
            text = text.split("```")[1].split("```")[0].strip()
            logger.debug("ğŸ”§ Removed markdown ``` wrapper")
        
        # ç§»é™¤BOMå’Œé›¶å®½å­—ç¬¦
        text = text.replace('\ufeff', '').replace('\u200b', '')
        
        # ğŸ”¥ CRITICAL FIX: ä¿®å¤å­—ç¬¦ä¸²å€¼å†…éƒ¨çš„æœªè½¬ä¹‰å¼•å·
        # è¿™æ˜¯Geminiç”ŸæˆJSONçš„æœ€å¸¸è§é—®é¢˜
        text = JSONValidator._fix_unescaped_quotes_in_strings(text)
        
        # ğŸ”¥ NEW: ä¿®å¤æ— å¼•å·çš„å±æ€§å (Geminiå¸¸è§é—®é¢˜)
        # åŒ¹é…æ¨¡å¼: { field_name: "value" } â†’ { "field_name": "value" }
        # ä»…åœ¨å¯¹è±¡å†…éƒ¨è¿›è¡Œæ›¿æ¢ï¼Œé¿å…è¯¯ä¼¤å­—ç¬¦ä¸²å†…å®¹
        original_text = text
        text = re.sub(
            r'([{,]\s*)([a-zA-Z_][a-zA-Z0-9_]*)\s*:',
            r'\1"\2":',
            text
        )
        
        # ğŸ”¥ DEBUG: æ£€æŸ¥æ˜¯å¦ä¿®å¤äº†æ— å¼•å·å±æ€§å
        if text != original_text:
            logger.debug(f"ğŸ”§ Fixed unquoted property names (changed {len(text) - len(original_text)} chars)")
            logger.debug(f"ğŸ“¤ After fix (first 200 chars): {text[:200]}")
        
        # ä¿®å¤å¸¸è§çš„è½¬ä¹‰é—®é¢˜
        # 1. å¤„ç†æœªè½¬ä¹‰çš„æ¢è¡Œç¬¦ï¼ˆåœ¨å­—ç¬¦ä¸²å†…ï¼‰
        text = re.sub(r'(?<!\\)"([^"]*)\n([^"]*)"', r'"\1\\n\2"', text)
        
        # 2. ä¿®å¤è¿ç»­çš„è½¬ä¹‰åæ–œæ 
        text = text.replace('\\\\n', '\\n').replace('\\\\t', '\\t')
        
        return text.strip()
    
    @staticmethod
    def _fix_unescaped_quotes_in_strings(text: str) -> str:
        """
        ä¿®å¤JSONå­—ç¬¦ä¸²å€¼å†…éƒ¨çš„æœªè½¬ä¹‰å¼•å·
        
        ä¾‹å¦‚: "text": "He said "hello" there" 
        ä¿®å¤ä¸º: "text": "He said \\"hello\\" there"
        
        ä½¿ç”¨ç®€åŒ–çš„æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•ï¼Œæ›´å¯é 
        """
        try:
            # ğŸ”¥ SIMPLE STRATEGY: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ‰¾åˆ°æ‰€æœ‰å­—ç¬¦ä¸²å€¼ï¼Œç„¶åä¿®å¤å…¶ä¸­çš„å¼•å·
            # æ¨¡å¼: "field_name": "value with possible "quotes" inside"
            
            def fix_quotes_in_match(match):
                """ä¿®å¤åŒ¹é…åˆ°çš„å­—ç¬¦ä¸²å€¼ä¸­çš„å¼•å·"""
                field_name = match.group(1)
                string_value = match.group(2)
                
                # åœ¨å­—ç¬¦ä¸²å€¼å†…éƒ¨è½¬ä¹‰æ‰€æœ‰æœªè½¬ä¹‰çš„å¼•å·
                # ä½†è¦å°å¿ƒå·²ç»è½¬ä¹‰çš„å¼•å·
                fixed_value = string_value
                
                # å…ˆæ ‡è®°å·²ç»è½¬ä¹‰çš„å¼•å·
                fixed_value = fixed_value.replace('\\"', '<<<ESCAPED_QUOTE>>>')
                
                # è½¬ä¹‰æ‰€æœ‰å‰©ä½™çš„å¼•å·
                fixed_value = fixed_value.replace('"', '\\"')
                
                # æ¢å¤å·²ç»è½¬ä¹‰çš„å¼•å·
                fixed_value = fixed_value.replace('<<<ESCAPED_QUOTE>>>', '\\"')
                
                return f'"{field_name}": "{fixed_value}"'
            
            # åŒ¹é…æ¨¡å¼ï¼šå±æ€§å: å€¼
            # å…è®¸å€¼åŒ…å«æ¢è¡Œå’Œå…¶ä»–å­—ç¬¦
            pattern = r'"([^"]+)"\s*:\s*"((?:[^"\\]|\\.)*?)(?="(?:\s*[,}\]])|$)'
            
            fixed = re.sub(pattern, fix_quotes_in_match, text, flags=re.DOTALL)
            
            if fixed != text:
                logger.info(f"ğŸ”§ Applied regex-based quote fixing")
                return fixed
            
            return text
            
        except Exception as e:
            logger.warning(f"âš ï¸ Regex quote fixing failed: {e}, trying character-by-character approach")
            
            # FALLBACK: å­—ç¬¦çº§åˆ«çš„ä¿®å¤ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            return JSONValidator._fix_unescaped_quotes_detailed(text)
    
    @staticmethod
    def _fix_unescaped_quotes_detailed(text: str) -> str:
        """
        è¯¦ç»†çš„å­—ç¬¦çº§åˆ«å¼•å·ä¿®å¤ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        """
        try:
            result = []
            i = 0
            in_string = False
            string_start_pos = -1
            
            while i < len(text):
                char = text[i]
                
                # æ£€æŸ¥è½¬ä¹‰å­—ç¬¦
                if char == '\\' and i + 1 < len(text):
                    result.append(char)
                    result.append(text[i + 1])
                    i += 2
                    continue
                
                # æ£€æŸ¥å¼•å·
                if char == '"':
                    # åˆ¤æ–­è¿™æ˜¯å±æ€§åçš„å¼•å·è¿˜æ˜¯å­—ç¬¦ä¸²å€¼çš„å¼•å·
                    # é€šè¿‡æŸ¥çœ‹å‰åä¸Šä¸‹æ–‡æ¥åˆ¤æ–­
                    
                    if not in_string:
                        # è¿›å…¥å­—ç¬¦ä¸²
                        in_string = True
                        string_start_pos = i
                        result.append(char)
                        i += 1
                        
                        # ğŸ”¥ å…³é”®ï¼šåˆ¤æ–­è¿™æ˜¯å±æ€§åè¿˜æ˜¯å€¼
                        # å¦‚æœåé¢ç´§è·Ÿç€å†’å·ï¼Œè¿™æ˜¯å±æ€§å
                        lookahead = i
                        while lookahead < len(text) and text[lookahead] in [' ', '\t', '\n', '\r']:
                            lookahead += 1
                        
                        if lookahead < len(text) and text[lookahead] == ':':
                            # è¿™æ˜¯å±æ€§åï¼Œç»§ç»­æŸ¥æ‰¾å±æ€§å€¼
                            while i < len(text) and text[i] != '"':
                                result.append(text[i])
                                i += 1
                            if i < len(text):
                                result.append(text[i])  # é—­åˆå±æ€§åçš„å¼•å·
                                i += 1
                            
                            # è·³è¿‡å†’å·å’Œç©ºç™½
                            while i < len(text) and text[i] in [':', ' ', '\t', '\n', '\r']:
                                result.append(text[i])
                                i += 1
                            
                            # ç°åœ¨åº”è¯¥æ˜¯å€¼çš„å¼€å§‹å¼•å·
                            if i < len(text) and text[i] == '"':
                                in_string = True
                                string_start_pos = i
                                result.append(text[i])
                                i += 1
                            else:
                                in_string = False
                        
                    else:
                        # å¯èƒ½æ˜¯å­—ç¬¦ä¸²ç»“æŸï¼Œä¹Ÿå¯èƒ½æ˜¯å†…éƒ¨æœªè½¬ä¹‰çš„å¼•å·
                        # æ£€æŸ¥åé¢æ˜¯å¦è·Ÿç€é€—å·ã€èŠ±æ‹¬å·æˆ–æ–¹æ‹¬å·
                        lookahead = i + 1
                        while lookahead < len(text) and text[lookahead] in [' ', '\t', '\n', '\r']:
                            lookahead += 1
                        
                        if lookahead < len(text) and text[lookahead] in [',', '}', ']']:
                            # è¿™æ˜¯å­—ç¬¦ä¸²ç»“æŸ
                            in_string = False
                            result.append(char)
                            i += 1
                        else:
                            # è¿™æ˜¯å†…éƒ¨æœªè½¬ä¹‰çš„å¼•å·ï¼Œéœ€è¦è½¬ä¹‰
                            logger.debug(f"ğŸ”§ Escaping unescaped quote at position {i}")
                            result.append('\\')
                            result.append(char)
                            i += 1
                else:
                    result.append(char)
                    i += 1
            
            fixed = ''.join(result)
            
            if fixed != text:
                # è®¡ç®—ä¿®å¤äº†å¤šå°‘å¤„
                fix_count = fixed.count('\\"') - text.count('\\"')
                if fix_count > 0:
                    logger.info(f"ğŸ”§ Fixed {fix_count} unescaped quotes via detailed analysis")
            
            return fixed
            
        except Exception as e:
            logger.warning(f"âš ï¸ Detailed quote fixing failed: {e}, returning original text")
            return text
    
    @staticmethod
    def _advanced_repair(text: str, expected_fields: List[str], error: json.JSONDecodeError) -> Optional[Dict]:
        """é«˜çº§JSONä¿®å¤ç­–ç•¥"""
        strategies = [
            JSONValidator._repair_unterminated_string,
            JSONValidator._repair_via_regex_extraction,
            JSONValidator._repair_truncated_json,
        ]
        
        for strategy in strategies:
            try:
                result = strategy(text, expected_fields, error)
                if result:
                    return result
            except Exception as e:
                logger.debug(f"Strategy {strategy.__name__} failed: {e}")
                continue
        
        return None
    
    @staticmethod
    def _repair_unterminated_string(text: str, expected_fields: List[str], error: json.JSONDecodeError) -> Optional[Dict]:
        """ä¿®å¤æœªç»ˆæ­¢çš„å­—ç¬¦ä¸² - å¢å¼ºç‰ˆï¼ˆæ”¯æŒ json-repair åº“ï¼‰"""
        if 'Unterminated string' not in str(error):
            return None
        
        # ğŸ”¥ PRIORITY 1: Try json-repair library first (most reliable)
        try:
            from json_repair import repair_json
            logger.info("ğŸ”§ Attempting json-repair library for unterminated string...")
            repaired = repair_json(text)
            if isinstance(repaired, dict):
                logger.success("âœ… json-repair library successfully fixed unterminated string")
                return repaired
        except ImportError:
            logger.debug("json-repair library not available, using manual repair")
        except Exception as e:
            logger.debug(f"json-repair failed: {e}, falling back to manual repair")
        
        # ğŸ”¥ PRIORITY 2: Manual repair strategies
        pos = error.pos if hasattr(error, 'pos') else -1
        if pos > 0 and pos < len(text):
            # Strategy 1: Find next delimiter and close string before it
            next_delimiter = pos
            for i in range(pos, min(pos + 200, len(text))):
                if text[i] in [',', '}', ']']:
                    next_delimiter = i
                    break
            
            # Try inserting closing quote at delimiter
            fixed_text = text[:next_delimiter] + '"' + text[next_delimiter:]
            try:
                return json.loads(fixed_text)
            except:
                pass
            
            # Strategy 2: Close string immediately and try to close JSON
            for ending in ['"}}', '"}', '","']:
                try:
                    fixed_text = text[:pos] + ending
                    return json.loads(fixed_text)
                except:
                    continue
        
        return None
    
    @staticmethod
    def _repair_via_regex_extraction(text: str, expected_fields: List[str], error: json.JSONDecodeError) -> Optional[Dict]:
        """é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æå–å­—æ®µå†…å®¹"""
        extracted = {}
        
        for field in expected_fields:
            # åŒ¹é… "field": "value" æ ¼å¼ï¼Œæ”¯æŒå¤šè¡Œå’Œè½¬ä¹‰å¼•å·
            pattern = rf'"{field}"\s*:\s*"((?:[^"\\]|\\.)*)(?:"|\Z)'
            match = re.search(pattern, text, re.DOTALL)
            
            if match:
                value = match.group(1)
                # åè½¬ä¹‰
                value = value.replace('\\"', '"').replace('\\n', '\n').replace('\\t', '\t')
                extracted[field] = value.strip()
            else:
                extracted[field] = "[Data extraction failed]"
        
        # éªŒè¯è‡³å°‘æå–äº†ä¸€åŠçš„å­—æ®µ
        valid_fields = [v for v in extracted.values() if v != "[Data extraction failed]"]
        if len(valid_fields) >= len(expected_fields) / 2:
            logger.info(f"ğŸ“ Regex extraction recovered {len(valid_fields)}/{len(expected_fields)} fields")
            return extracted
        
        return None
    
    @staticmethod
    def _repair_truncated_json(text: str, expected_fields: List[str], error: json.JSONDecodeError) -> Optional[Dict]:
        """ä¿®å¤è¢«æˆªæ–­çš„JSON"""
        # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å­—æ®µ
        last_complete = text.rfind('",')
        if last_complete > 0:
            # æˆªå–åˆ°æœ€åä¸€ä¸ªå®Œæ•´å­—æ®µï¼Œæ·»åŠ é—­åˆæ‹¬å·
            truncated = text[:last_complete + 1] + '\n}'
            
            try:
                data = json.loads(truncated)
                # è¡¥å……ç¼ºå¤±å­—æ®µ
                for field in expected_fields:
                    if field not in data:
                        data[field] = "[Data truncated]"
                
                logger.info(f"ğŸ”§ Repaired truncated JSON, recovered {len(data)} fields")
                return data
            except:
                pass
        
        return None


class JSONInspector:
    """JSONæ£€æŸ¥å®˜ - éªŒè¯JSONå®Œæ•´æ€§å’Œè´¨é‡"""
    
    QUALITY_THRESHOLDS = {
        'min_length_per_field': 50,  # æ¯ä¸ªå­—æ®µæœ€å°‘50å­—ç¬¦
        'placeholder_patterns': [
            r'\[Data not available\]',
            r'\[Insufficient data\]',
            r'\[Unknown\]',
            r'\.\.\.',
            r'N/A',
        ],
        'max_placeholder_ratio': 0.3,  # æœ€å¤š30%çš„å­—æ®µå¯ä»¥æ˜¯å ä½ç¬¦
    }
    
    @staticmethod
    def inspect_quality(data: Dict[str, Any], section_name: str = "Unknown") -> Dict[str, Any]:
        """
        æ£€æŸ¥JSONæ•°æ®è´¨é‡
        
        Args:
            data: å¾…æ£€æŸ¥çš„æ•°æ®
            section_name: ç« èŠ‚åç§°
        
        Returns:
            è´¨é‡æŠ¥å‘Šå­—å…¸
        """
        report = {
            'section': section_name,
            'total_fields': len(data),
            'issues': [],
            'quality_score': 10.0,
            'recommendations': []
        }
        
        placeholder_count = 0
        short_field_count = 0
        
        for field, value in data.items():
            str_value = str(value)
            
            # æ£€æŸ¥å ä½ç¬¦
            is_placeholder = any(
                re.search(pattern, str_value, re.IGNORECASE) 
                for pattern in JSONInspector.QUALITY_THRESHOLDS['placeholder_patterns']
            )
            
            if is_placeholder:
                placeholder_count += 1
                report['issues'].append(f"Field '{field}' contains placeholder text")
            
            # æ£€æŸ¥å­—æ®µé•¿åº¦
            if len(str_value) < JSONInspector.QUALITY_THRESHOLDS['min_length_per_field']:
                short_field_count += 1
                report['issues'].append(f"Field '{field}' is too short ({len(str_value)} chars)")
        
        # è®¡ç®—è´¨é‡åˆ†æ•°
        placeholder_ratio = placeholder_count / len(data) if data else 1.0
        short_ratio = short_field_count / len(data) if data else 1.0
        
        # æ‰£åˆ†é€»è¾‘
        if placeholder_ratio > JSONInspector.QUALITY_THRESHOLDS['max_placeholder_ratio']:
            deduction = (placeholder_ratio - 0.3) * 20
            report['quality_score'] -= deduction
            report['recommendations'].append(
                f"âš ï¸ High placeholder ratio ({placeholder_ratio:.1%}). Request more detailed content."
            )
        
        if short_ratio > 0.4:
            report['quality_score'] -= short_ratio * 15
            report['recommendations'].append(
                f"âš ï¸ Many fields are too short. Request expanded analysis."
            )
        
        report['quality_score'] = max(0, report['quality_score'])
        
        # ç”Ÿæˆæ€»ç»“
        if report['quality_score'] >= 8:
            report['verdict'] = "âœ… EXCELLENT"
        elif report['quality_score'] >= 6:
            report['verdict'] = "âš ï¸ ACCEPTABLE"
        else:
            report['verdict'] = "âŒ POOR - Regeneration recommended"
        
        logger.info(f"ğŸ” Quality inspection: {report['verdict']} (Score: {report['quality_score']:.1f}/10)")
        
        return report


class SegmentedJSONGenerator:
    """åˆ†æ®µJSONç”Ÿæˆç®¡ç†å™¨ - å°†å¤§JSONæ‹†åˆ†æˆå°å—ç”Ÿæˆ"""
    
    # å®šä¹‰æŠ¥å‘Šçš„å„ä¸ªæ®µè½å’Œå¯¹åº”å­—æ®µ
    REPORT_SEGMENTS = {
        'metadata': {
            'fields': ['compound_name', 'moa_description', 'target_description', 
                      'development_stage', 'sponsor_company', 'market_context'],
            'description': 'Project metadata and basic information',
            'max_tokens': 1500
        },
        'summary': {
            'fields': ['executive_summary', 'red_flags_list', 'decision_factors'],
            'description': 'Executive summary and key findings',
            'max_tokens': 2000
        },
        'analysis': {
            'fields': ['scientific_rationale', 'clinical_trial_analysis'],
            'description': 'Scientific and clinical analysis',
            'max_tokens': 2500
        },
        'evidence': {
            'fields': ['dark_data_synthesis', 'forensic_findings'],
            'description': 'Dark data and forensic findings',
            'max_tokens': 2000
        },
        'risk': {
            'fields': ['risk_cascade_narrative', 'failure_timeline'],
            'description': 'Risk analysis and timeline',
            'max_tokens': 2000
        },
        'scenarios': {
            'fields': ['bull_case', 'bear_case', 'black_swan_case', 'analyst_verdict'],
            'description': 'Investment scenarios and verdict',
            'max_tokens': 2000
        }
    }
    
    @staticmethod
    def get_segment_prompt(segment_key: str, base_prompt: str, evidence_summary: str) -> str:
        """
        ç”Ÿæˆç‰¹å®šæ®µè½çš„prompt
        
        Args:
            segment_key: æ®µè½é”®å
            base_prompt: åŸºç¡€promptæ¨¡æ¿
            evidence_summary: è¯æ®æ‘˜è¦
        
        Returns:
            å®Œæ•´çš„segment prompt
        """
        segment_info = SegmentedJSONGenerator.REPORT_SEGMENTS[segment_key]
        
        prompt = f"""You are generating the '{segment_key}' section of a biomedical due diligence report.

**SEGMENT FOCUS:** {segment_info['description']}

**REQUIRED FIELDS:**
{json.dumps(segment_info['fields'], indent=2)}

{evidence_summary}

**CRITICAL JSON FORMATTING REQUIREMENTS:**
1. Generate ONLY the fields listed above
2. ALL property names MUST be enclosed in double quotes ("field_name":)
3. Return VALID JSON - test your output with a JSON parser before responding
4. Each field should contain substantial content (minimum 100 words for analysis fields)
5. Cite sources using [Source: PMC/PMID] or [Trial: NCT] format
6. DO NOT use placeholder text like "[Data not available]" unless truly no data exists
7. Ensure all strings are properly terminated with closing quotes
8. NO markdown code fences (no ```json), NO explanatory text - ONLY JSON

**STRICT OUTPUT FORMAT:**
Return ONLY a valid JSON object. Start with {{ and end with }}. Nothing else.

Example (note the quoted property names):
{{{{
  "field_name_1": "Detailed content here...",
  "field_name_2": "More detailed content..."
}}}}

âš ï¸ VALIDATION: Your response will be parsed with json.loads(). If it fails, generation will be rejected.

{base_prompt}
"""
        return prompt
    
    @staticmethod
    def merge_segments(segments: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆå¹¶å¤šä¸ªæ®µè½çš„JSONæ•°æ®
        
        Args:
            segments: æ®µè½å­—å…¸ï¼Œkeyä¸ºsegment_keyï¼Œvalueä¸ºè¯¥æ®µè½çš„æ•°æ®
        
        Returns:
            åˆå¹¶åçš„å®Œæ•´æ•°æ®å­—å…¸
        """
        merged = {}
        
        for segment_key in SegmentedJSONGenerator.REPORT_SEGMENTS.keys():
            if segment_key in segments:
                merged.update(segments[segment_key])
            else:
                logger.warning(f"âš ï¸ Missing segment: {segment_key}")
                # è¡¥å……ç¼ºå¤±æ®µè½çš„å­—æ®µ
                segment_info = SegmentedJSONGenerator.REPORT_SEGMENTS[segment_key]
                for field in segment_info['fields']:
                    merged[field] = "[Segment generation failed]"
        
        logger.success(f"âœ… Merged {len(segments)}/{len(SegmentedJSONGenerator.REPORT_SEGMENTS)} segments")
        return merged
